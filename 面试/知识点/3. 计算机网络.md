### 3.1 TCP

TCP的三次握手及四次握手（腾讯云一面，腾讯云二面，今日头条一面，腾讯CDG一面，==腾讯CDG事务开发一面==，==字节系统研发一面==）

> 三次握手
> 
> > 1. 客户端请求建立连接，发送`SYN`消息，进入`SYN_SEND`状态
> > 2. 服务端收到`SYN`消息，发送`ACK+SYN`的消息，进入`SYN_RENC`消息
> > 3. 客户端收到`ACK+SYN`的消息，发送`ACK`消息，双方收到后进行`ESTABLISHED`状态
> 
> 四次挥手
> 
> > 1. 客户端无数据发送，发送`FIN`消息，进入 `FIN_WAIT_1` 状态
> > 2. 服务端收到`FIN`消息，发送`ACK` 消息，客户端收到进入 `FIN_WAIT_2` 状态；
> > 3. 服务端无待发送数据，发送 `FIN` 消息；
> > 4. 客户端收到 `FIN` 消息，进入 `TIME_WAIT` 状态，发送 `ACK` 消息，服务端收到进入 `CLOSED` 状态；
> > 5. 客户端等待两个最大数据段生命周期（Maximum segment lifetime，MSL），进入`CLOSED` 状态
> 
> 为什么三次握手而不是两次握手
> 
> > 主要为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。如客户端发出连接请求，可能因为网络阻塞原因，客户端没有收到确认报文，于是客户端再重传一次连接请求。连接成功，等待数据传输完毕后，就释放了连接。而客户端发出的第一个连接请求等到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端不理睬服务端的确认且不发送数据，则服务端一直等待客户端发送数据，浪费资源。
> 
> 为什么连接的时候的时候是三次握手，关闭的时候是四次挥手？
> 
> > 因为当服务端端收到客户端端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端端收到连接释放报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端：“你发的连接释放报文我收到了”。只有等到服务端端所有的报文都发送完了，才能发送连接释放报文，因此不能一起发送。故需要四步握手。
> 
> TCP的Time_wait状态
> 
> > [为什么 TCP 协议有 TIME_WAIT 状态](https://draveness.me/whys-the-design-tcp-time-wait/)
> > 
> > [TCP的TIME_WAIT状态](https://zhuanlan.zhihu.com/p/99943313)
> > 
> > `TIME_WAIT`仅在主动断开连接的一方出现，被动断开连接的一方会直接进入`CLOSED`，进入`TIME_WAIT`的客户端需要等待两个最大数据段生命周期(MSL)。
> > 
> > 原因：
> > 
> > 1. 允许老的重复报文分组在网络中消逝
> > 2. 保证TCP全双工连接的正确关闭
> > 
> > 第一个理由是假如我们在`192.168.1.1:5000`和`39.106.170.184:6000`建立一个TCP连接，一段时间后我们关闭这个连接，再基于相同插口建立一个新的TCP连接，这个新的连接称为前一个连接的化身。老的报文很有可能由于某些原因迟到了，那么新的TCP连接很有可能会将这个迟到的报文认为是新的连接的报文，而导致数据错乱。**为了防止这种情况的发生TCP连接必须让TIME_WAIT状态持续`2MSL`，在此期间将不能基于这个插口建立新的化身**，让它有足够的时间使迟到的报文段被丢弃。
> > 
> > 第二个理由是因为如果主动关闭方最终的`ACK`丢失，那么服务器将会重新发送那个`FIN`,以允许主动关闭方重新发送那个`ACK`。要是主动关闭方不维护`2MSL`状态，那么主动关闭将会不得不响应一个`RST`报文段，而服务器将会把它解释为一个错误，导致TCP连接没有办法完成全双工的关闭，而进入半关闭状态。
> > 
> > 为什么是维持2MSL
> > 
> > 1. 一个`MSL`是确保主动关闭方最后的`ACK`能到达对端；
> > 2. 一个`MSL`是确保被动关闭方重发的`FIN`能够被主动关闭方收到
> > 
> > 在`RFC793`中规定的`MSL`时间为2min，在实际使用中一般是30s或者1min，在高并发的情况下毫无疑问，将会造成大量连接无法建立的问题。

第二次握手，客户端一直没有收到ACK会发生什么事情（腾讯云二面，==腾讯CDG事务开发一面==）

> 客户端在等待了两个最大数据段生命周期后，会认为自己的发送能力和对方的接受能力有问题，然后进行超时重传

TCP和UDP的区别（华为Cloudbu一面，腾讯CDG一面，==Lazada一面==，==百度一面==）

> - TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接
> 
> - TCP提供可靠的服务；UDP不保证可靠交付
> 
> - TCP面向字节流，把数据看成一连串无结构的字节流;UDP是面向报文的
> 
> - TCP有拥塞控制；UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
> 
> - 每一条TCP连接只能是点到点的；UDP支持一对一，一对多，多对一和多对多的交互通信
> 
> - TCP首部开销20字节；UDP的首部开销小，只有8个字节

UDP如何变成可靠的协议（==百度一面==）

> [UDP如何实现可靠传输](https://www.jianshu.com/p/6c73a4585eba)
> 
> 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。
> 
> - 1、添加seq/ack机制，确保数据发送到对端
> - 2、添加发送和接收缓冲区，主要是用户超时重传。
> - 3、添加超时重传机制。
> 
> 详细说明：发送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

TCP为什么是可靠的（今日头条一面）

> 1. 应用数据被分割成TCP认为最合适发送的数据块。
> 2. TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据发送给应用层
> 3. **校验和**：TCP将保持它首部和数据的校验和。这是一个端到端的校验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP会丢弃这个报文段和不确认收到此报文段
> 4. TCP的接收端会丢弃重复的数据
> 5. **流量控制**：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。（TCP使用滑动窗口实现流量控制）
> 6. **拥塞控制**：当网络拥塞时，减少数据的发送；
> 7. **ARP协议**：也是为了实现可靠传输的，它的基本原理就是每发送完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；
> 8. **超时重传**：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

超时重传等待时间的计算（腾讯云二面）

为什么HTTP协议是基于TCP（今日头条一面）

> TCP是一个端到端的可靠的面向连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当错误时，会重传）

TCP的拥塞机制（深信服一面，腾讯云二面，==百度一面==）

> ![TCP的拥塞控制（详解）7](https://res-static.hc-cdn.cn/fms/img/a7741d3223791e04828b06cf566a6bf71603441882876.png)
> 
> 拥塞窗口（cwnd）与发送窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口
> 
> - 慢开始与拥塞避免。
>   - 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...
>   - 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1
>   - 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始
> - 快重传与快恢复
>   - 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。
>   - 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
>   - 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

切分后乱序是怎么处理的呢？（腾讯CDG一面）

> [老铁意向+ 很多tcp的总结](https://www.nowcoder.com/discuss/530380?type=2&channel=-2&source_id=discuss_tag_discuss_hot)

一个消息报的长度在哪个地方会有限制？（腾讯CDG一面）

> 传输层

TCP还有其他拥塞机制吗（腾讯云二面）

### 3.2 HTTP

HTTP和HTTPS的区别，对称加密和非对称加密，HTTPS的加密过程（华为Cloudbu一面，腾讯云一面，==腾讯CDG事务开发一面==，==Lazada一面==）

> [HTTPS 详解一：附带最精美详尽的 HTTPS 原理图](https://segmentfault.com/a/1190000021494676)
> 
> 一、HTTP和HTTPS的区别
> 
> > 1、**端口**：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认端口443
> > 
> > 2、**安全性和资源消耗**：
> > 
> > - HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务端都无法验证对方的身份。
> > - HTTPS是运行在SSL（安全套接层）/TLS（安全传输层协议）之上的HTTP协议，SSL/TLS运行在TCP之上，所有传输的内容都经过加密，加密采用对称加密，但对称加密的秘钥用服务器方的证书进行了非对称加密。
> > - 所以说，HTTP安全性没有HTTPS高，但是HTTPS比HTTP消耗更多服务器资源。
> > 
> > 3、使用 HTTPS 协议需要申请 CA 证书，一般免费证书较少，因而需要一定费用。
> 
> 二、对称加密与非对称加密
> 
> > 1、对称加密。加密和解密都使用同一个密钥，常见的对称加密算法有 DES、3DES 和 AES
> > 
> > - 优点：算法公开、计算量小、加密速度快、加密效率高，适合加密比较大的数据。
> > - 缺点：
> >   1. 交易双方需要使用相同的密钥，也就无法避免密钥的传输，而密钥在传输过程中无法保证不被截获，因此对称加密的安全性得不到保证。
> >   2. 每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一密钥，这会使得发收信双方所拥有的钥匙数量急剧增长，[密钥管理](https://link.segmentfault.com/?url=http%3A%2F%2Fbaike.baidu.com%2Fview%2F297229.htm)成为双方的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。
> > 
> > 2、非对称加密。加密和解密需要使用两个不同的密钥：公钥（public key）和私钥（private key）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。
> > 
> > - 优点：算法公开，加密和解密使用不同的钥匙，私钥不需要通过网络进行传输，安全性很高。
> > - 缺点：计算量比较大，加密和解密速度相比对称加密慢很多。
> 
> 三、HTTPS的加密过程
> 
> > 1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。
> > 2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。
> > 3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。
> > 4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。
> > 5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。
> > 6. 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。
> > 7. 服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。
> > 8. 双方使用对称加密愉快地传输所有数据。

HTTP常见的请求方法（华为Cloudbu一面）

> 一、常用的请求方法
> 
> **GET** 获取资源；**HEAD** 获取报文首部；**POST** 传输实体主体；**PUT** 上传文件；**PATCH** 对资源进行部分修改；**DELETE** 删除文件；**OPTIONS** 查询支持的方法；**CONNECT** 要求在与代理服务器通信时建立隧道；**TRACE** 追踪路径
> 
> 二、GET和POST的区别
> 
> - GET请求参数通过URL传递，POST的参数放在请求体中。
> 
> - GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把请求头和请求体一并发送出去；而对于POST，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体。
> 
> - GET请求会被浏览器主动缓存，而POST不会，除非手动设置。
> 
> - GET请求只能进行url编码，而POST支持多种编码方式。
> 
> - GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。

HTTP的响应码有哪些（华为Cloudbu一面，腾讯CDG一面）

> ![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)
> 
> - **100 Continue**：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
> 
> - **200 OK**
> 
> - **204 No Content**：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
> 
> - **301 Moved Permanently**：永久性重定向
> 
> - **302 Found**：临时性重定向
> 
> - **400 Bad Request**：请求报文中存在语法错误。
> 
> - **401 Unauthorized**：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
> 
> - **403 Forbidden**：请求被拒绝。
> 
> - **404 Not Found**
> 
> - **500 Internal Server Error**：服务器正在执行请求时发生错误。
> 
> - **503 Service Unavailable**：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

HTTP消息的结构？（腾讯CDG一面）

> 请求报文结构：
> 
> - 第一行是包含了请求方法、URL、协议版本；
> - 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。
> - 一个空行用来分隔首部和内容主体 Body
> - 最后是请求的内容主体
> 
> 响应报文结构：
> 
> - 第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了
> - 接下来多行也是首部内容
> - 一个空行分隔首部和内容主体
> - 最后是响应的内容主体

gRPC和HTTP的区别（==华为公共开发一面==）

> [HTTP，TCP， socket，RPC 与gRPC都是啥？](https://www.jianshu.com/p/959030de7f1c)
> 
> 一、HTTP, TCP, socket, RPC与gRPC的概念
> 
> > - TCP是传输层协议，主要解决数据如何在网络中传输
> > - HTTP 是应用层协议，主要解决如何包装数据（文本信息），是建立在tcp协议之上的应用。
> > - TCP协议是以二进制数据流的形式解决传输层的事儿，但对上层的应用开发极不友好，所以面向应用层的开发又产生了HTTP协议。
> > - socket 是针对TCP或UDP的具体接口实现，提供了在传输层进行网络编程的方法。
> > - RPC跟HTTP不是对立面，RPC中可以使用HTTP作为通讯协议。**RPC是一种设计、实现框架，通讯协议只是其中一部分。**RPC需要解决的问题：
> >   - 建立通信：在客户端与服务端建立起数据传输通道，大都是TCP连接（gRPC使用了HTTP2）。
> >   - 寻址：A服务器上的应用需要告诉RPC框架：B服务器地址、端口，调用函数名称。所以必须实现待调用方法到call ID的映射。
> >   - 序列化与反序列化：由于网络协议都是二进制的，所以调用方法的参数在进行传递时首先要序列化成二进制，B服务器收到请求后要再对参数进行反序列化。恢复为内存中的表达方式，找到对应的方法进行本地调用，得到返回值。返回值从B到A的传输仍要经过序列化与反序列化的过程。
> > - gRPC是谷歌开源的一个 RPC 框架，面向移动和 HTTP/2 设计。
> >   - 内容交换格式采用ProtoBuf(Google Protocol Buffers)，开源已久，提供了一种灵活、高效、自动序列化结构数据的机制，作用与XML，Json类似，但使用二进制，（反）序列化速度快，压缩效率高。
> >   - 传输协议 采用http2，性能比http1.1好了很多
> 
> 二、HTTP1.0和HTTP1.1的区别
> 
> > - **长连接**：HTTP1.0默认使用短连接，每次请求都需要建立新的TCP连接，连接不能复用。HTTP1.1支持长连接，复用TCP连接。
> > 
> > - **缓存处理**：在HTTP1.0中主要使用header里的`If-Modified-Since,Expires`来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。
> > 
> > - **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
> > 
> > - **错误通知的管理**：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
> > 
> > - **Host头处理**：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
> 
> 三、HTTP1.1和HTTP2.0的区别
> 
> > - **新的二进制格式**：HTTP 1.x的解析是基于文本，HTTP 2.0的解析采用二进制，实现方便，健壮性更好。
> > - **多路复用**。多个request共享一个连接。
> > - **header压缩**。在HTTP1.x中header信息很多，且每次都会重复发送，造成很大浪费。HTTP2.0使用encoder减少了传输的header大小，且通信双方都缓存一份包含了header信息的表，此后的请求可以只发送差异数据，避免信息的重复传输，进一步减少需要传输的内容大小。
> > - **服务端推送**。客户端在请求一个资源时，服务端会把相关资源一起发给客户端，这样客户端就不需要再次发起请求。

### 3.3 其他

OSI的七层模型有哪些（华为Cloudbu一面，==字节系统研发一面==）

> ![五层体系结构](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E4%BA%94%E5%B1%82%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png)
> 
> - 应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、SMTP协议等。
> 
> - 表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
> 
> - 会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户登录便是由会话层完成的。
> 
> - 运输层：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。
> 
> - 网络层：为主机提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。
> 
> - 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。
> 
> - 物理层：物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

输入域名到页面发生渲染会发生什么？DNS的解析过程？（今日头条一面，今日头条测开二面，==Lazada一面==）

> 输入域名到页面发生渲染会发生什么？
> 
> 1. 对[www.baidu.com这个网址进行DNS域名解析，得到对应的IP地址；](http://www.baidu.com%E8%BF%99%E4%B8%AA%E7%BD%91%E5%9D%80%E8%BF%9B%E8%A1%8CDNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%EF%BC%8C%E5%BE%97%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84IP%E5%9C%B0%E5%9D%80%EF%BC%9B)
> 2. 根据这个IP，找到对应的服务器，发起TCP的三次握手；
> 3. 建立TCP连接后发起HTTP请求；
> 4. 服务器响应HTTP请求，浏览器得到html代码；
> 5. 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）；
> 6. 浏览器对页面进行渲染呈现给用户；
> 7. 服务器关闭TCP连接；
> 
> DNS的解析过程？[面试：DNS解析过程和原理（7000字）](https://blog.csdn.net/weixin_44523860/article/details/110352555)
> 
> 1. 浏览器搜索自己的DNS缓存
> 
> 2. 若没有，则搜索操作系统中的DNS缓存和hosts文件
> 
> 3. 若没有，则操作系统将域名发送至本地域名服务器，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向根域名服务器、顶级域名服务器、权限域名服务器发起查询请求，最终返回IP地址给本地域名服务器
> 
> 4. 本地域名服务器将得到的IP地址返回给操作系统，同时自己也将IP地址缓存起来
> 
> 5. 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来
> 
> 6. 浏览器得到域名对应的IP地址

应用层常用的端口？（腾讯CDG一面）

> | 应用        | 应用层协议  | 端口号     | 传输层协议   | 备注                 |
> | --------- | ------ | ------- | ------- | ------------------ |
> | 域名解析      | DNS    | 53      | UDP/TCP | 长度超过 512 字节时使用 TCP |
> | 动态主机配置协议  | DHCP   | 67/68   | UDP     |                    |
> | 简单网络管理协议  | SNMP   | 161/162 | UDP     |                    |
> | 文件传送协议    | FTP    | 20/21   | TCP     | 控制连接 21，数据连接 20    |
> | 远程终端协议    | TELNET | 23      | TCP     |                    |
> | 超文本传送协议   | HTTP   | 80      | TCP     |                    |
> | 超文本传输安全协议 | HTTPS  | 443     | TCP     |                    |
> | 简单邮件传送协议  | SMTP   | 25      | TCP     |                    |
> | 邮件读取协议    | POP3   | 110     | TCP     |                    |
> | 网际报文存取协议  | IMAP   | 143     | TCP     |                    |

网络常见的IO模型？select和poll（今日头条一面，今日头条测开二面，==腾讯CDG事务开发一面==，==百度一面==，==超参数一面==）

> 一、I/O模型
> 
> 一个输入操作通常包括两个阶段：
> 
> - 等待数据准备好
> - 从内核向进程复制数据
> 
> 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。
> 
> 1、阻塞式I/O
> 
> 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
> 
> 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。
> 
> 下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。
> 
> ```
> ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
> ```
> 
> [![img](https://camo.githubusercontent.com/68a3f48b4948ac53d220664a56429c5e84c0667ff640d6038c6e9dced48da9e1/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383431363831325f342e706e67)](https://camo.githubusercontent.com/68a3f48b4948ac53d220664a56429c5e84c0667ff640d6038c6e9dced48da9e1/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383431363831325f342e706e67)
> 
> 2、非阻塞式I/O
> 
> 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。
> 
> 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。
> 
> [![img](https://camo.githubusercontent.com/ecac1a2f263b198fa5660f7dd5a9accce515f49d6f7256a87fa1410049a1debe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393030303336315f352e706e67)](https://camo.githubusercontent.com/ecac1a2f263b198fa5660f7dd5a9accce515f49d6f7256a87fa1410049a1debe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393030303336315f352e706e67)
> 
> 3、I/O复用
> 
> 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。
> 
> 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。
> 
> 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。
> 
> [![img](https://camo.githubusercontent.com/aa49b130631537882aa3d8338f3e8edd4136aca31ba5b8f84b7bd1c2a3049bc8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393434343831385f362e706e67)](https://camo.githubusercontent.com/aa49b130631537882aa3d8338f3e8edd4136aca31ba5b8f84b7bd1c2a3049bc8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393434343831385f362e706e67)
> 
> 4、信号驱动I/O
> 
> 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。
> 
> 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。
> 
> [![img](https://camo.githubusercontent.com/4ef6a2ee94e21ab9b8365a59a480fbbd44f375fd98da42873b5fcbb15530411e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393535333635315f372e706e67)](https://camo.githubusercontent.com/4ef6a2ee94e21ab9b8365a59a480fbbd44f375fd98da42873b5fcbb15530411e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393535333635315f372e706e67)
> 
> 5、异步I/O
> 
> 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。
> 
> 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。
> 
> [![img](https://camo.githubusercontent.com/4e523f16614b51e79c78bcf61234201ae4ca5b36b2bc4bb24572ee2622fe458c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323933303234333238365f382e706e67)](https://camo.githubusercontent.com/4e523f16614b51e79c78bcf61234201ae4ca5b36b2bc4bb24572ee2622fe458c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323933303234333238365f382e706e67)
> 
> 6、五大I/O模型比较
> 
> - 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
> - 异步 I/O：第二阶段应用进程不会阻塞。
> 
> 同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。
> 
> 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。
> 
> [![img](https://camo.githubusercontent.com/e5ec41f6e0278716f715bfbd28b9a401684f1373cc5d979b34da21d5a1c7f2ef/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383130353739315f332e706e67)](https://camo.githubusercontent.com/e5ec41f6e0278716f715bfbd28b9a401684f1373cc5d979b34da21d5a1c7f2ef/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383130353739315f332e706e67)
> 
> 二、I/O复用
> 
> 1、select
> 
> ```c
> int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
> ```
> 
> select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。
> 
> - fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。
> - timeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。
> - 成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。
> 
> 2、poll
> 
> ```c
> int poll(struct pollfd *fds, unsigned int nfds, int timeout);
> ```
> 
> poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。
> 
> poll 中的描述符是 pollfd 类型的数组，pollfd 的定义如下：
> 
> ```c
> struct pollfd {
> int   fd;         /* file descriptor */
> short events;     /* requested events */
> short revents;    /* returned events */
> };
> ```
> 
> 3、比较
> 
> select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。
> 
> - select 会修改描述符，而 poll 不会；
> - select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
> - poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
> - 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。
> 
> select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
> 
> 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。
> 
> 4、epoll
> 
> ```
> int epoll_create(int size);
> int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
> int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
> ```
> 
> epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。
> 
> 从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
> 
> epoll 仅适用于 Linux OS。
> 
> epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
> 
> epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。
> 
> 工作模式
> 
> - **LT模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
> - **ET模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
> 
> 5、应用场景
> 
> select应用场景
> 
> - select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。
> - select 可移植性更好，几乎被所有主流平台所支持。
> 
> poll应用场景
> 
> - poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
> 
> epoll应用场景
> 
> - 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。
> - 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
> - 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。
