### 零、简历

实习时间（腾讯音乐一面，快手一面，快手二面，腾讯CDG一面，深信服一面，深信服二面，腾讯云一面，今日头条测开二面）

介绍简历中的论文（华为Cloudbu一面，快手一面）

在做研究的过程中有什么难点（华为Cloudbu一面）

论文的创新性（华为Cloudbu一面）

论文有没有一些实际的应用（华为Cloudbu一面）

本科和研究生的成绩（华为Cloudbu一面）

本科有去实习过吗（快手一面）

为什么想转到互联网？（今日头条一面）

想做的方向（腾讯TEG一面）

最近才开始后端开发和WEB开发嘛？（今日头条一面）

个人比较倾向于后台开发比较相关的？（今日头条一面）

开源的好处和坏处（深信服二面）

从安全角度来看，开源有什么风险，会带来哪些安全隐患（深信服二面）

项目亮点（腾讯音乐一面，腾讯CDG一面）

项目中最大的挑战？有什么难点？（淘宝一面，快手一面，阿里3一面）

你心目中的架构是怎么的？从部署和分布式方面？（淘宝一面）

> [架构到底是指什么？](https://zhuanlan.zhihu.com/p/57141837)

### 一、项目

#### 1.1 实习简历

在线商城是看开源项目还是自己从头撸的？（今日头条一面，淘宝一面，深信服二面，腾讯云二面）

这个项目能很好地扩容到分布式嘛？（淘宝一面）

在线商城项目的架构设计（快手二面）

项目中是否应到哪些HTTP请求方法（华为Cloudbu一面）

在线商城系统是否应用到响应码（华为Cloudbu一面）

用户从搜索到下单的业务流程（腾讯TEG一面）

> 用户进行搜索，先利用ES进行一个倒排索引的查询，查询到指定商品后，进行下单，后端检测到该商品被锁定后，利用Redis进行上锁。用户下单后，数据库中对应商品数减1。

取消超时订单操作是怎么做的？（腾讯CDG一面，淘宝一面）

> - 用户下单后，生成订单id；
> - 获取到设置的订单超时时间（假设设置的为60分钟不支付取消订单）；
> - 按订单超时时间发送一个延迟消息给Kafka，让它在订单超时后触发取消订单的操作；
> - 如果没有支付，进行取消订单

为什么使用RabbitMQ，而不是采用其它消息队列？（深信服二面）

> RabbitMQ和Kafka的区别：
>
> - 通常会使用Kafka作为消息传输的数据管道，RabbitMQ作为交易数据作为数据传输管道，主要的取舍因素则是存在丢数据的可能
> - RabbitMQ在金融场景下经常使用，具有较高的严谨性，数据丢失的可能性更小，同时具备更高的实时性
> - Kafka优势主要体现在吞吐量上，虽然可以通过策略实现数据不丢失，但从严谨性角度来讲，大不如RabbitMQ
> - 而且由于Kafka保证每条数据最少送达一次，有较小的概率会出现数据重复发送的情况

提交超时订单为什么要用消息队列？而不用Redis的超时清理？（深信服一面）

用户登录与授权是怎么实现安全性的？（今日头条一面，深信服二面）

> 主要使用JWT实现用户登录与授权的安全性。
>
> - 用户调用登录接口，登录成功后获取到JWT的token；
> - 之后用户每次调用接口都在http的header中添加一个叫Authorization的头，值为JWT的token；
> - 后台程序通过对Authorization头中的信息解码及数字签名验证来获取其中的用户信息，从而实现登录和授权

怎么处理JWT中的token过期的事情？（今日头条一面）

> [JWT生成token及过期处理方案](https://my.oschina.net/odetteisgorgeous/blog/1920762)
>
> - 基本思路
>   - token(A)过期设置为15分钟
>   - 前端发起请求，后端验证token(A)是否过期
>     - 如果过期，前端发起刷新token请求，后端设置已在此标记为true，请求成功
>   - 前端发起请求，后端验证再次授权标记
>     - 如果已经再次授权，则拒绝token的请求，请求成功
>   - 如果前端每隔72小时，必须重新登陆，后端检查用户最后依次登录日期
>     - 如超过72小时，则拒绝刷新token的请求，请求失败
> - 后端
>   - 在登陆接口中 如果校验账号密码成功 则根据用户id和用户类型创建jwt token(有效期设置为-1，即永不过期) 得到A
>   - 更新登录日期(当前时间new Date()即可)，得到B
>   - 
>   - \redis中缓存key为`ACCESS_TOKEN:userId:A`(加上A是为了防止用户多个客户端登录 造成token覆盖),value为B的毫秒数（转换成字符串类型），过期时间为7天（7 * 24 * 60 * 60）
>   - 在登录结果中返回json格式为`{"result":"success","token": A}`
>   - 用户在接口请求header中携带token进行登录，后端在所有接口前置拦截器进行拦截，作用是解析token 拿到userId和用户类型（用户调用业务接口只需要传token即可）
>     - 如果解析失败（抛出SignatureException），则返回json（code = 0 ,info= Token验证不通过, errorCode = '1001'）； 
>   - 此外如果解析成功，验证redis中key为`ACCESS_TOKEN:userId:A `是否存在 
>     - 如果不存在 则返回json（code = 0 ,info= 会话过期请重新登录, errorCode = '1002'）； 
>     - 如果缓存key存在，则自动续7天超时时间（value不变），实现频繁登录用户免登陆。
>   - 把userId和用户类型放入request参数中 接口方法中可以直接拿到登录用户信息
>   - 如果是修改密码或退出登录 则废除access_tokens（删除key）
> - 前端(VUE)
>   - 用户登录成功，则把username存入cookie中，key为loginUser;把token存入cookie中，key为accessToken 把token存入Vuex全局状态中
>   - 进入首页

地震监控后台优化

> - 缓存优化
>   - 优化原因
>     - 在原先用户登录时，或者切换其他站点查看地震监控数据时，都会从亚马逊云端读取粗糙数据并在后台进行计算后返回给前端，造成了时间复杂度的大幅度增加。
>   - 改进
>     - 增加了缓存优化，在服务器端维护了一个缓存区，将初次登录的计算的结果进行缓存，从而避免在切换站点时进行反复时的重复计算。在退出登录时，这个缓冲区会被删除。
>
> - 异步优化
>   - 优化原因
>     - 同样是在后台进行计算时返回前端时，事实上，计算的部分中间结果就可以返回给前端，但是却加上需要计算最终结果并与亚马逊云端进行通过
>   - 改进
>     - 使用线程池ThreadPoolExecutor 增加异步操作，先将中间结果返回给前端，并较给线程在后台执行耗时任务。

Redis数据缓存和分布式锁做的是什么？（快手一面，淘宝一面，腾讯云二面）

> 手机验证码功能。根据手机号生成随机的验证码并设置过期时间，存储在Redis中。使用到了String数据结构。
>
> Redis分布式锁主要利用Redis的setnx命令。
>
> - 加锁命令：`SETNX key value`，当键不存在时，对键进行设置操作并返回成功，否则返回失败。
>   - `key`是锁的唯一标识，一般按业务来决定命名，`value`可以使用`uuid`来保证唯一；
> - 解锁命令：`DEL key`，通过删除键值对释放锁，以便其他线程可以通过SETNX命令来获取锁；
> - 锁超时：`EXPIRE key timeout`，设置key的超时时间，以保证即使锁没有被显式释放，锁也可以在第一时间后自动释放，避免资源用于被锁住。

为什么会想到用到分布式锁？（快手一面，深信服一面，腾讯云二面）

> 如果在一个分布式系统中，我们从数据库中读取一个数据，然后修改保存，这种情况很容易遇到并发问题。因此读取和更新保存不是一个原子操作，在并发时就会导致数据的不正确性。比如电商秒杀活动，库存数量的更新就是遇到。如果单机应用，直接使用本地锁就可以避免。如果是分布式应用，本地锁派不上用场，这时就需要引入分布式锁来解决。
>
> 分布式锁的目的是为了保证多台服务器在执行某一段代码时保证只有一台服务器执行。

是一个商品一个锁吗？如何防止一个用户锁定了多个商品？（深信服一面）

> 是一个商品一个锁，因为Redis是单线程的且基于IO复用模型的，因此不会出现一个用户锁定多个商品的情况

锁是否真的实现商品被超购（腾讯云二面）

SETNX是原子操作吗？不是原子操作会出现什么问题（腾讯云二面）

> SETNX和EXPIRE是非原子性的
>
> 如果SETNX成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致EXPIRE命令没有被执行，锁没有设置超时时间变成死锁
>
> 解决方法：
>
> ```lua
> if (redis.call('setnx', KEYS[1], ARGV[1]) < 1)
> then return 0;
> end;
> redis.call('expire', KEYS[1], tonumber(ARGV[2]));
> return 1;
> 
> // 使用实例
> EVAL "if (redis.call('setnx',KEYS[1],ARGV[1]) < 1) then return 0; end; redis.call('expire',KEYS[1],tonumber(ARGV[2])); return 1;" 1 key value 100
> ```

#### 1.2 秋招简历

链路追踪的调研（==字节系统研发一面==）

追踪的原理（==字节系统研发一面==）

> 基本概念
>
> - Trace就表示一个完整的调用链
>
> - span表示一个RPC调用
> - 使用grpc发送数据至落库（ES）
>
> Java 使用字节码增强进行接入，在运行Java命令时指定agent的位置
>
> [Dapper,大规模分布式系统的跟踪系统](https://cloud.tencent.com/developer/article/1031932)

链路追踪的作用，技术选型的依据（==百度一面==）

为什么选consul作为微服务注册中心（==百度一面==）

consul如何进行服务发现、注册中心、熔断、限流（==百度一面==）

> Consul 官网中介绍了 Consul 的以下几个核心功能：
>
> - **服务发现(Service Discovery)**：提供 HTTP 与 DNS 两种方式。
> - **健康检查(Health Checking)**：提供多种健康检查方式，比如 HTTP 状态码、内存使用情况、硬盘等等。
> - **键值存储(KV Store)**：可以作为服务配置中心使用，类似 Spring Cloud Config。
> - **加密服务通信(Secure Service Communication)**
> - **多数据中心(Multi Datacenter)**：Consul 通过 WAN 的 Gossip 协议，完成跨数据中心的同步。
>
> 负载均衡由客户端实现，从注册中心拿到要访问的服务的ip列表后，使用轮询
>
> 降级是指突发流量来了，保住核心服务，非核心就不接流量了
>
> 熔断是下游挂了，不访问下游返回默认

#### 1.3 场景题

一亿个视频，一亿个用户，统计每个视频被多少个用户播放（腾讯云一面）

一个仓库，需要出货，每个货物具有不同的优先级，设计一个程序来优先出货优先级比较高的货物。相同优先级的货品如何排列（腾讯云二面）

说一下手机播放视频失败的原因（今日头条测开二面）

大文件的查询，想做一个关键词查询（今日头条测开二面）

数据存在MySQL数据库中，这些数据是否是明文的？如果一些框架出现安全问题，要怎样保证数据库中的数据的安全？（深信服二面）

Redis如果整个集群都掉电挂了，且没有持久化，怎么办（腾讯TEG一面）

在数据结构中，一个亿的无序数据如何快速取前面100个（腾讯TEG一面）

### 二、Java 基础

==和equals有什么区别（华为Cloudbu一面，腾讯CDG一面）

> - ==对于基本类型来说是值比较，对于引用类型来说是比较的引用；
> - String、Integer重写了equals方法，一般情况下equals比较的是值是否相等。

StringBuilder和StringBuffer（华为Cloudbu一面）

> 可变性：
>
> - String不可变
> - StringBuffer和StringBuilder可变
>
> 线程安全：
>
> - String不可变，因此是线程安全的
> - StringBuilder不是线程安全的
> - StringBuffer是线程安全的，内部使用synchronized进行同步

接口和抽象类的区别（华为Cloudbu一面，淘宝一面，腾讯TEG一面）

> - 实现。抽象类的子类使用extends来继承（定义抽象类就是让其他类继承的），接口必须使用implements来实现接口；
>
> - 构造函数。抽象类可以有构造函数；接口不能有
> - main方法。抽象类可以有main方法，并且我们能运行它；接口不能有main方法。
> - 实现数量。类可以实现很多个接口；但是只能继承一个抽象类
> - 访问修饰符。接口中的方法默认使用public修饰；抽象类中的方法可以是任意访问修饰符。

继承和重载（华为Cloudbu一面）

> 继承：子类可以使用父类中的一些成员变量和方法，使用extends关键字实现
>
> 重载：是指一个类中定义了多个重名方法，它们的参数列表是不相同的。

Java异常的类型（华为Cloudbu一面）

> <div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/PPjwP.png" width="600"/> </div><br>

解释一下Java的序列化和反序列化？什么时候会用到？序列化的底层实现（腾讯CDG一面，深信服一面）

> - 序列化就是将一个对象转换为字节序列，方便存储和传输
>   - 序列化：ObjectOuputStream.writeObject()
>   - 反序列化：ObjectInputStream.readObject()
> - 不会对静态变量进行初始化，因为序列化只是保存对象的状态，静态变量属于类的状态
> - 序列化的类需要实现Serializable接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常
> - transient关键字可以使一些熟悉不会被序列化

Java的泛型（深信服一面）

> 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。

Java和Python的区别，各自有什么缺点？（深信服二面，今日头条测开二面）

> - Java必须显式声明变量名，而动态类型的Python不需要声明变量
> - Python虚拟机没有Java强，Java虚拟机是Java的核心，Python的核心是可以很方便地使用c语言函数或c++库
> - Java是一种静态类型语言，Python是一种动态类型语言
> - Java 的类型要声明，Python 的类型不需要
> - Python是全动态性的，可以在运行时自己修改自己的代码，Java只能通过变通方法实现

python是怎么执行的，需要编译链接吗？（今日头条测开二面）

> [python程序需要编译吗](https://cloud.tencent.com/developer/article/1725774)
>
> 因为 Python 代码在运行前，会先编译（翻译）成中间代码，每个 .py 文件将被换转成 .pyc 文件，.pyc 就是一种字节码文件，它是与平台无关的中间代码，不管你放在 Windows 还是 Linux 平台都可以执行，运行时将由虚拟机逐行把字节码翻译成目标代码。
>
> [Java到底是编译型语言还是解释型语言？](https://blog.fundebug.com/2019/01/25/is-java-a-compiled-or-an-interpreted-programming-language/)
>
> java是解释型的语言，因为虽然java也需要编译，编译成.class文件，但是并不是机器可以识别的语言，而是字节码，最终还是需要 jvm的解释，才能在各个平台执行，这同时也是java跨平台的原因。所以可是说java即是编译型的，也是解释型，但是假如非要归类的话，从概念上的定义，恐怕java应该归到解释型的语言中

面向对象和面向过程的区别（阿里3一面）

> - 面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了
> - 面向对象事把构成问题事物分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描述某个事物在解决问题的步骤中的行为

面向对象中的设计原则？使用了什么设计模式？（阿里3一面）

> - 单一责任原则。
>   - 修改一个类的原因只有一个
>   - 换句话说就是让一个类只负责一件事，当这个类需要做过多事情的时候，就需要分解这个类。
>   - 如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱这个类完成其他职责的能力
> - 开放封闭原则
>   - 类应该对扩展开放，对修改关闭
>   - 扩展就是添加新功能的意思，因此该原则要求在添加新功能时不需要修改代码
>   - 符合开闭原则最典型的设计模式是装饰者模式，它可以动态地将责任附加到对象上，而不用去修改类的代码
> - 里氏替换原则
>   - 子类必须能够替换掉所有父类对象
>   - 继承是一种 IS-A 关系，子类需要能够当成父类来使用，并且需要比父类更特殊。
>   - 如果不满足这个原则，那么各个子类的行为上就会有很大差异，增加继承体系的复杂度。
> - 接口分离原则
>   - 不应该强迫客户依赖于它们不用的方法。
>   - 因此使用多个专门的接口比使用单一的总接口要好。
> - 依赖倒置原则
>   - 高层模块不应该依赖于低层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。
>   - 高层模块包含一个应用程序中重要的策略选择和业务模块，如果高层模块依赖于低层模块，那么低层模块的改动就会直接影响到高层模块，从而迫使高层模块也需要改动。
>   - 依赖意味着
>     - 任何变量都不应该持有一个指向具体类的指针或者引用；
>     - 任何类都不应该从具体类派生；
>     - 任何方法都不应该覆写它的任何基类中的已经实现的方法。

设计模式有什么用？（阿里3一面）

> 为了代码可重用性、增加可维护性，让代码更容易被他人理解、保证代码可靠性。设计模式使代码真正工程化。

Java动态代理的场景（腾讯CDG一面）

> - 静态代理
>   - 概念
>     - 静态代理其实就是设计模式中的代理模式；
>     - 代理模式为其它对象提供一种代理以控制对这个对象的访问
>   - 缺点
>     - 大量使用这种静态代理，会使我们系统内的类的规模增大，并不易于维护；
>     - 并且由于Proxy和RealSubject的功能本质上是相同的，Proxy只是起到了中介的作用，这种代理在系统中的存在，导致系统结构比较臃肿和松散
> - 动态代理
>   - 概念
>     - 在运行状态中，需要代理的地方，根据Subject和RealSubject，动态地创建一个Proxy，用完之后，就会销毁，这样就可以避免Proxy角色的class在系统中冗余的问题了。
>     - Java动态代理基于经典代理模式，引入了一个InvocationHandler，InvocationHandler负责统一管理所有的方法调用。
>     - 基于Java内部的反射机制完成的
>   - 步骤
>     - 获取RealSubject上的所有接口列表
>     - 确定要生成的代理类的类名，默认为：com.sun.proxy.$ProxyXXXX
>     - 根据需要实现的接口信息，在代码中动态创建该Proxy类的字节码
>     - 将对应的字节码转换为对应的class对象
>     - 创建InvocationHandler实例handler，用来处理Proxy所有方法调用
>     - Proxy的class对象以创建的handler对象为参数，实例化一个proxy对象

Java的反射机制？（深信服一面）

> [深入理解Java反射](https://zhuanlan.zhihu.com/p/60805342)
>
> 通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。
>
> - **优点** ： 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利
> - **缺点** ：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。

### 三、Java 虚拟机

JVM的内存模型（==百度一面==）

> ![img](https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9FJDK1.8.png)
>
> 一、程序计数器
>
> 程序计数器是线程私有的，它的生命周期与线程相同，主要有两个作用：
>
> 1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
> 2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。
>
> 二、Java虚拟机栈
>
> - Java 虚拟机栈也是线程私有的，它的生命周期和线程相同
> - 描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。
> - Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。
>
> 三、本地方法栈
>
> - 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。
>
> 四、堆
>
> - Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。
> - 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。
>
> 五、方法区
>
> - 方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

垃圾回收算法（腾讯CDG一面，腾讯TEG一面，深信服一面，==百度一面==）

> 一、判断对象是否可以被回收
>
> 1、引用计数算法。
>
> - 为对象添加一个引用计数器，当对象增加一个引用时计数器加1，引用失效时计数器减1。
> - 引用计数为0的对象可被回收。但是当出现循环引用时，此时计数器永远不为0，导致无法对它们进行回收。
>
> 2、可达性分析算法
>
> - 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收
> - Java 虚拟机使用该算法来判断对象是否可被回收
>
> 二、垃圾回收算法
>
> 1、标记-清除算法
>
> 该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。这种垃圾收集算法会带来两个明显的问题：
>
> - **效率问题**
>
> - **空间问题（标记清除后会产生大量不连续的碎片）**
>
> 2、标记-复制算法
>
> 为了解决效率问题，“标记-复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。
>
> 3、标记-整理算法
>
> 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。
>
> 4、分代收集算法
>
> **比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**
>
> 三、垃圾收集器
>
> 1、[Serial 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_41-serial-收集器)
>
> Serial（串行）收集器不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。
>
> 它**简单而高效（与其他收集器的单线程相比）**。
>
> **新生代采用标记-复制算法，老年代采用标记-整理算法。**
>
> ![ Serial 收集器 ](https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/46873026.png)
>
> 2、[ParNew 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_42-parnew-收集器)
>
> **ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。**
>
> **新生代采用标记-复制算法，老年代采用标记-整理算法。**
>
> ![ParNew 收集器 ](https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/22018368.png)
>
> 3、[Parallel Scavenge 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_43-parallel-scavenge-收集器)
>
> **Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。** 
>
> **新生代采用标记-复制算法，老年代采用标记-整理算法。**
>
> ![Parallel Scavenge 收集器 ](https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/parllel-scavenge%E6%94%B6%E9%9B%86%E5%99%A8.png)
>
> 4、[Serial Old 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_44serial-old-收集器)
>
> **Serial 收集器的老年代版本**，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。
>
> 5、[Parallel Old 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_45-parallel-old-收集器)
>
> **Parallel Scavenge 收集器的老年代版本**。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。
>
> 6、[CMS 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_46-cms-收集器)
>
> **CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。**
>
> **CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。**CMS 收集器是一种 **“标记-清除”算法**实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：
>
> - **初始标记：** 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
> - **并发标记：** 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
> - **重新标记：** 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
> - **并发清除：** 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。
>
> ![CMS 垃圾收集器 ](https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/CMS%E6%94%B6%E9%9B%86%E5%99%A8.png)
>
> 主要优点：**并发收集、低停顿**。但是它有下面三个明显的缺点：
>
> - **对 CPU 资源敏感；**
> - **无法处理浮动垃圾；**
> - **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**
>
> 7、[G1 收集器](https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM垃圾回收?id=_47-g1-收集器)
>
> - **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
> - **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
> - **空间整合**：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
> - **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。
>
> **G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。

JVM的引用回收的计数器保存在哪里？（深信服一面）

> [对象引用计数保存在哪里？](https://blog.csdn.net/WangErice/article/details/105095579)

stop the world在哪些阶段发生（腾讯TEG一面）

> 垃圾回收时，必须暂停其他所有工作线程

在JVM和类加载的过程如何实现多态（腾讯云一面）

new一个对象的过程，从创建到垃圾回收，双亲委派机制（今日头条一面，腾讯CDG一面，腾讯云二面，==华为公共开发一面==）

> [java new一个对象的过程中发生了什么](https://www.cnblogs.com/JackPn/p/9386182.html)
>
> ![img](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B-%E5%AE%8C%E5%96%84.png)
>
> 一、类加载过程
>
> 1、加载
>
> 由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例
>
> 2、验证
>
> 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求
>
> 3、准备
>
> 为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内）
>
> 4、解析
>
> 将常量池的符号引用替换为直接引用的过程。
>
> 其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。
>
> 5、初始化
>
> - 为静态变量赋值
>
> - 执行static代码块
>
> 因为子类存在对父类的依赖，所以**类的加载顺序是先加载父类后加载子类，初始化也一样。**不过，父类初始化时，子类静态变量的值也有有的，是默认值。
>
> 最终，方法区会存储当前类类信息，包括类的**静态变量**、**类初始化代码**（**定义静态变量时的赋值语句** 和 **静态初始化代码块**）、**实例变量定义**、**实例初始化代码**（**定义实例变量时的赋值语句实例代码块**和**构造方法**）和**实例方法**，还有**父类的类信息引用。**
>
> 二、创建对象
>
> 1、在堆区分配对象需要的内存
>
> - 分配的内存包括本类和父类的所有实例变量，但不包括任何静态变量
>
> 2、对所有实例变量赋默认值
>
> - 将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值
>
> 3、执行实例初始化代码
>
> - 初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法
>
> 4、如果有类似于Child c = new Child()形式的c引用的话，在栈区定义Child类型引用变量c，然后将堆区对象的地址赋值给它
>
> 三、双亲委派机制
>
> ![ClassLoader](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/classloader_WPS%E5%9B%BE%E7%89%87.png)
>
> 有一个类需要类加载器去加载，如果有父类，先让父类去加载，如此往上追朔，直到根类加载器，然后根类加载器尝试去加载，加载成功则结束，加载失败，又往下，一层层的尝试去加载，最终如果没有加载成功，则报错ClassNotFound。

### 四、Java 容器

Java的容器有哪些？（华为Cloudbu一面，腾讯CDG一面）

> 容器：
>
> - Collection。存储对象的集合
>   - Set
>     - TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如HashSet，HashSet查找的时间复杂度为O(1)，TreeSet为O(logn)。
>     - HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并失去了元素的插入顺序信息，也就是说使用Iterator遍历HashSet得到的结果是不确定的。
>     - LinkedHashSet：具有HashSet的查找效率，并且内部使用双向链表维护元素的插入顺序。
>   - List
>     - ArrayList：基于动态数组实现，支持随机访问。
>     - Vector：和ArrayList类似，但它是线程安全的
>     - LinkedList：基于双向链表实现，只能顺序访问，但是可以快速在链表中间插入和删除元素。不仅如此，LinkedList还可以用于栈、队列和双向队列。
>   - Queue
>     - LinkedList：可以用它来实现双向队列
>     - PriorityQueue：基于堆结构实现，可以用它来实现优先队列。
> - Map
>   - TreeMap：基于红黑树实现
>   - HashMap：基于哈希表实现
>   - HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程同时写入 HashTable 不会导致数据不一致。它是遗留类，不应该去使用它，而是使用 ConcurrentHashMap 来支持线程安全，ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。
>   - LinkedHashMap：使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。

Java HashMap是怎么实现的（今日头条一面，阿里3一面，==百度一面==）

> JDK1.8 之前 `HashMap` 由数组+链表组成的，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间

如果HashMap的链表过长是否会影响查找效率（阿里3一面）

HashMap为什么是线程不安全的？（腾讯CDG一面）

> - 多线程的put可能导致元素的丢失
> - put和get并发时，可能导致get为null
> - JDK7中并发put会造成循环链表，导致get出现死循环

JDK8 HashMap是否会导入死循环？（阿里3一面）

> 主要原因在于并发下的 Rehash 会造成元素之间会形成一个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。
>
> 详情请查看：https://coolshell.cn/articles/9606.html

HashMap为什么大于8要转换为红黑树（今日头条一面）

> 理想情况下，在随机哈希码下，哈希表中节点 的频率遵循泊松分布，而且根据统计，忽略方差，列表长度为K的期望出现的次数是以上的结果，可以看到其实在8的时候概率就已经很小了，再往后调整并没有很大意义。

concurrentHashMap如何扩容？（腾讯CDG一面）

> - 当前键值对的数量大于loadFactor✖capacity时即进行扩容
> - 当需要扩容时，令capacity为原来的两倍
> - 扩容操作使用resize()实现，需要把oldTable的所有键值对重新插入newTable中

HashMap和ConcureentHashMap的区别？HashMap如何实现线程安全？ConcurentHashMap锁的实现，是在哪一个版本实现的，哪一个版本进行改进（腾讯CDG一面，腾讯云二面，==百度一面==）

> JDK1.7
>
> 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。
>
> **`ConcurrentHashMap` 是由 `Segment` 数组结构和 `HashEntry` 数组结构组成**。
>
> Segment 实现了 `ReentrantLock`,所以 `Segment` 是一种可重入锁，扮演锁的角色。`HashEntry` 用于存储键值对数据。
>
> JDK1.8
>
> `ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 CAS 和 `synchronized` 来保证并发安全。数据结构跟 HashMap1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）
>
> `synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。

向两个HashMap分别put1000条和10000条数据，并且其初始容量为1000和100000，在put的过程中会进行扩容吗（腾讯云一面）

> 会啊，HashMap允许的size小于loadFactor×capacity，因此会进行扩容

concurrentHashMap的size如何计算（腾讯云一面）

红黑树的特点，平衡二叉树和红黑树的区别，查询和插入的时间复杂度（阿里3一面，腾讯云二面，==百度一面==）

> [红黑树深入剖析及Java实现](https://tech.meituan.com/2016/12/02/redblack-tree.html)
>
> 1. 任何一个节点都有颜色，黑色或者红色
>2. 根节点是黑色的
> 3. 父子节点之间不能出现两个连续的红节点
> 4. 任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等
> 5. 空节点被认为是黑色的
> 
> 红黑树在插入、删除等操作，不会像平衡树那样，频繁着破坏红黑树的规则，所以不需要频繁地调整。红黑树在最坏情况下，也能在O(logn)地时间复杂度下查找某个节点
>
> 整个红黑树的查找，插入和删除都是O(logN)的

红黑树在Java中的应用（腾讯云二面）

### 五、Java 并发

线程的创建的几种方法？Callable和Runnable的区别（华为Cloudbu一面，腾讯CDG一面）

> 一、线程创建的几种方法
>
> - 实现Runnable接口；
> - 实现Callable接口；
> - 继承Thread类
>
> 二、Callable和Runnable的区别
>
> - `Runnable`自 Java 1.0 以来一直存在，但`Callable`仅在 Java 1.5 中引入，目的就是为了来处理`Runnable`不支持的用例。
> - `Runnable` 接口 不会返回结果或抛出检查异常，但是 `Callable` 接口可以。

死锁的概念？如何避免死锁？(淘宝一面，==腾讯CDG事务开发一面==)

>  一、死锁的概念
>
>  多个线程同时被阻塞，它们中的一个或多个全部都在同时等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止
>
>  二、死锁的四个必要条件以及死锁避免
>
>  1、互斥
>
>  - 每个资源要么已经分配给一个进程，要么就是可用的；
>  - 无法破坏，因为我们用锁本来就是希望让它们互斥的
>
>  2、请求和保持
>
>  - 已经得到了某个资源的进程可以再请求新的资源；
>  - 破坏方法：一次性申请所有的资源
>
>  3、不可抢占
>
>  - 已经分配给一个进程的资源不能强制性地抢占，它只能被占有它的进程显式地释放
>  - 破坏方法：占有部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源
>
>  4、环路等待
>
>  - 有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源
>  - 破坏方法：按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放
>

synchronized的实现原理（腾讯TEG一面）

> - synchronized本质上是对对象监视器monitor的获取
>
> - 监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。
>
> - 如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

偏向锁和轻量级锁的实现（腾讯TEG一面）

> [Java6及以上版本对synchronized的优化](https://www.cnblogs.com/wuqinglong/p/9945618.html)
>
> - 偏向锁。偏向锁是针对于一个线程而言的, 线程获得锁之后就不会再有解锁等操作了, 这样可以省略很多开销. 假如有两个线程来竞争该锁话, 那么偏向锁就失效了, 进而升级成轻量级锁了。
>
> - 轻量级锁。线程会去循环地通过CAS去获取对象的锁。这个循环是有次数限制地，如果在循环结束之前CAS操作成功，则线程获取成功，否则则升级为重量级锁
>
> | 锁       | 优点                                                         | 缺点                                            | 适用场景                           |
> | -------- | ------------------------------------------------------------ | ----------------------------------------------- | ---------------------------------- |
> | 偏向锁   | 加锁和解锁不需要额外的消耗, 和执行非同步代码方法的性能相差无几. | 如果线程间存在锁竞争, 会带来额外的锁撤销的消耗. | 适用于只有一个线程访问的同步场景   |
> | 轻量级锁 | 竞争的线程不会阻塞, 提高了程序的响应速度                     | 如果始终得不到锁竞争的线程, 使用自旋会消耗CPU   | 追求响应时间, 同步快执行速度非常快 |
> | 重量级锁 | 线程竞争不适用自旋, 不会消耗CPU                              | 线程堵塞, 响应时间缓慢                          | 追求吞吐量, 同步快执行时间速度较长 |
>
> 首先要明确一点是引入这些锁是为了提高获取锁的效率, 要明白每种锁的使用场景, 比如偏向锁适合一个线程对一个锁的多次获取的情况; 轻量级锁适合锁执行体比较简单(即减少锁粒度或时间), 自旋一会儿就可以成功获取锁的情况。

synchronized和volatile的区别（==百度一面==）

> - `volatile` 关键字是线程同步的轻量级实现，所以 `volatile `性能肯定比`synchronized`关键字要好。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
> - `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
> - `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性。

volatile保持可见性的原理（==百度一面==）

> 把变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。
>
> 所以，**`volatile` 关键字 除了防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性。**
>
> ![volatile关键字的可见性](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-8/d49c5557-140b-4abf-adad-8aac3c9036cf.png)

synchronized和ReenterantLock的区别，ReenterantLock的使用场景（腾讯TEG一面）

> 1、两者都是可重入锁
>
> **“可重入锁”** 指的是自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增 1，所以要等到锁的计数器下降为 0 时才能释放锁。
>
> 2、synchronized依赖于JVM而ReentrantLock依赖于API
>
> - `synchronized` 是依赖于 JVM 实现的，并没有直接暴露给我们。
> - `ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。
>
> 3、ReentrantLock比synchronized增加了一些高级功能
>
> 相比`synchronized`，`ReentrantLock`增加了一些高级功能。主要来说主要有三点：
>
> - **等待可中断** : `ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
> - **可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过 `ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
> - **可实现选择性通知（锁可以绑定多个条件）**: `synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。

什么是happen-before原则？（阿里3一面）

> 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。
>
> happens-before原则：
>
> - 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前
> - 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系执行的结果一致，那么这种重排序并不非法

CAS（阿里3一面）

> CAS：Compare and Swap，翻译成比较并交换
>
> CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做

Java线程状态有哪些？（腾讯CDG一面）

> ![Java 线程的状态 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)
>

多线程下，i++和++i是否是线程安全？使用volatile是否可以使它线程安全？（阿里3一面）

> [i++使线程安全的吗](https://segmentfault.com/a/1190000015401766)
>
> [long和double的线程安全问题](https://blog.csdn.net/qq_32924343/article/details/79083094)
>
> - 每个线程都有自己的工作内存，每个线程需要对共享变量操作时必须先把共享变量从主内存load到自己的工作内存，等完成对共享变量的操作时再save到主内存
> - 如果一个线程运算完后还没有刷到主内存，此时这个共享变量的值就被另一个主线程从主内存读取到了，这个时候读取的数据就是脏数据，它会覆盖其他线程计算完的值
> - 加上volatile让内存可见不能解决这个问题。因为volatile只能保证可见性，不能保证原子性。多个线程同时读到这个共享变量的值，就算保证其他线程修改的可见性，也不能保证线程之间读取到相同值然后相互覆盖对方的值的情况
> - 解决方法
>   - 对i++操作的方法加同步锁，同步只能有一个线程执行i++操作
>   - 使用自持原子性操作的类，如Java.util.concurrent.atomic.AtomicInteger，它使用的是CAS算法

多线程加锁的方式？（腾讯CDG一面）

> - synchronized关键字
> - ReentrantLock实现类

ThreadLocal（腾讯CDG一面）

> `ThreadLocal`类主要解决的就是让每个线程绑定自己的值，使用`ThreadLocl`类来存储每个线程的私有数据。从而避免了线程安全问题。

Java如何创建线程池/线程池有哪几种，怎么使用（腾讯云二面、华为Cloudbu一面）

>1、通过构造方法实现。ThreadPoolExecutor
>
>2、通过Executor框架的工具类Executors来实现
>
>- FixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
>- SingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照执行顺序（FIFO，LIFO，优先级）执行
>- CachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可以灵活回收空闲线程，若无可回收，则新建线程；

线程池在比较繁忙的时候也永远达不到最大的线程数，线程池参数的意义（腾讯云一面）

核心线程数，最大线程，阻塞队列和拒绝策略的概念（腾讯云二面）

> [Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)
>
> ![图解线程池实现原理](https://snailclimb.gitee.io/javaguide/docs/java/multi-thread/images/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png)
>
> 1. 首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务
> 2. 如果workerCount<corePoolSize，则创建并启动一个线程来执行新提交的任务
> 3. 如果workerCount>=corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中
> 4. 如果workerCount>=corePoolSize&&workerCount<maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务
> 5. 如果workerCount>=maximumPoolSize，并且线程池内的阻塞队列已满，则根据拒绝策略来处理该任务，默认的处理方式是直接抛异常
>
> 拒绝策略：
>
> 1. AbortPolicy。抛出RejectedExecution来拒绝新任务的处理
> 2. CallerRunsPolicy
>    - 调用执行自己的线程运行任务。但这个策略会降低对于新任务的提交速度，影响程序的整体性能。
>    - 另外这个策略喜欢增加队列容量
>    - 如果应用程序可以承受此延迟并且不能丢弃任何一个请求的话，可以选择这个策略
> 3. DiscardPolicy。不处理新任务，直接丢弃掉
> 4. DiscardOldestPolicy。丢弃最早的未处理的任务请求
>

java交替打印（==百度一面==）

### 六、计算机网络

#### 6.1 TCP

TCP的三次握手及四次握手（腾讯云一面，腾讯云二面，今日头条一面，腾讯CDG一面，==腾讯CDG事务开发一面==，==字节系统研发一面==）

> 三次握手
>
> > 1. 客户端请求建立连接，发送`SYN`消息，进入`SYN_SEND`状态
> > 2. 服务端收到`SYN`消息，发送`ACK+SYN`的消息，进入`SYN_RENC`消息
> > 3. 客户端收到`ACK+SYN`的消息，发送`ACK`消息，双方收到后进行`ESTABLISHED`状态
>
> 四次挥手
>
> > 1. 客户端无数据发送，发送`FIN`消息，进入 `FIN_WAIT_1` 状态
> > 2. 服务端收到`FIN`消息，发送`ACK` 消息，客户端收到进入 `FIN_WAIT_2` 状态；
> > 3. 服务端无待发送数据，发送 `FIN` 消息；
> > 4. 客户端收到 `FIN` 消息，进入 `TIME_WAIT` 状态，发送 `ACK` 消息，服务端收到进入 `CLOSED` 状态；
> > 5. 客户端等待两个最大数据段生命周期（Maximum segment lifetime，MSL），进入`CLOSED` 状态
>
> 为什么三次握手而不是两次握手
>
> > 主要为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。如客户端发出连接请求，可能因为网络阻塞原因，客户端没有收到确认报文，于是客户端再重传一次连接请求。连接成功，等待数据传输完毕后，就释放了连接。而客户端发出的第一个连接请求等到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端不理睬服务端的确认且不发送数据，则服务端一直等待客户端发送数据，浪费资源。
>
> 为什么连接的时候的时候是三次握手，关闭的时候是四次挥手？
>
> > 因为当服务端端收到客户端端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端端收到连接释放报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端：“你发的连接释放报文我收到了”。只有等到服务端端所有的报文都发送完了，才能发送连接释放报文，因此不能一起发送。故需要四步握手。
>
> TCP的Time_wait状态
>
> > [为什么 TCP 协议有 TIME_WAIT 状态](https://draveness.me/whys-the-design-tcp-time-wait/)
> >
> > [TCP的TIME_WAIT状态](https://zhuanlan.zhihu.com/p/99943313)
> >
> > `TIME_WAIT`仅在主动断开连接的一方出现，被动断开连接的一方会直接进入`CLOSED`，进入`TIME_WAIT`的客户端需要等待两个最大数据段生命周期(MSL)。
> >
> > 原因：
> >
> > 1. 允许老的重复报文分组在网络中消逝
> > 2. 保证TCP全双工连接的正确关闭
> >
> > 第一个理由是假如我们在`192.168.1.1:5000`和`39.106.170.184:6000`建立一个TCP连接，一段时间后我们关闭这个连接，再基于相同插口建立一个新的TCP连接，这个新的连接称为前一个连接的化身。老的报文很有可能由于某些原因迟到了，那么新的TCP连接很有可能会将这个迟到的报文认为是新的连接的报文，而导致数据错乱。**为了防止这种情况的发生TCP连接必须让TIME_WAIT状态持续`2MSL`，在此期间将不能基于这个插口建立新的化身**，让它有足够的时间使迟到的报文段被丢弃。
> >
> > 第二个理由是因为如果主动关闭方最终的`ACK`丢失，那么服务器将会重新发送那个`FIN`,以允许主动关闭方重新发送那个`ACK`。要是主动关闭方不维护`2MSL`状态，那么主动关闭将会不得不响应一个`RST`报文段，而服务器将会把它解释为一个错误，导致TCP连接没有办法完成全双工的关闭，而进入半关闭状态。
> >
> > 为什么是维持2MSL
> >
> > 1. 一个`MSL`是确保主动关闭方最后的`ACK`能到达对端；
> > 2. 一个`MSL`是确保被动关闭方重发的`FIN`能够被主动关闭方收到
> >
> > 在`RFC793`中规定的`MSL`时间为2min，在实际使用中一般是30s或者1min，在高并发的情况下毫无疑问，将会造成大量连接无法建立的问题。

第二次握手，客户端一直没有收到ACK会发生什么事情（腾讯云二面，==腾讯CDG事务开发一面==）

> 客户端在等待了两个最大数据段生命周期后，会认为自己的发送能力和对方的接受能力有问题，然后进行超时重传

TCP和UDP的区别（华为Cloudbu一面，腾讯CDG一面，==Lazada一面==，==百度一面==）

> - TCP面向连接；UDP是无连接的，即发送数据之前不需要建立连接 
>
> - TCP提供可靠的服务；UDP不保证可靠交付 
>
> - TCP面向字节流，把数据看成一连串无结构的字节流;UDP是面向报文的 
>
> - TCP有拥塞控制；UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等） 
>
> - 每一条TCP连接只能是点到点的；UDP支持一对一，一对多，多对一和多对多的交互通信 
>
> - TCP首部开销20字节；UDP的首部开销小，只有8个字节

UDP如何变成可靠的协议（==百度一面==）

> [UDP如何实现可靠传输](https://www.jianshu.com/p/6c73a4585eba)
>
> 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。
>
> - 1、添加seq/ack机制，确保数据发送到对端
> - 2、添加发送和接收缓冲区，主要是用户超时重传。
> - 3、添加超时重传机制。
>
> 详细说明：发送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

TCP为什么是可靠的（今日头条一面）

> 1. 应用数据被分割成TCP认为最合适发送的数据块。
> 2. TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据发送给应用层
> 3. **校验和**：TCP将保持它首部和数据的校验和。这是一个端到端的校验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP会丢弃这个报文段和不确认收到此报文段
> 4. TCP的接收端会丢弃重复的数据
> 5. **流量控制**：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。（TCP使用滑动窗口实现流量控制）
> 6. **拥塞控制**：当网络拥塞时，减少数据的发送；
> 7. **ARP协议**：也是为了实现可靠传输的，它的基本原理就是每发送完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；
> 8. **超时重传**：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

超时重传等待时间的计算（腾讯云二面）

为什么HTTP协议是基于TCP（今日头条一面）

> TCP是一个端到端的可靠的面向连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当错误时，会重传）

TCP的拥塞机制（深信服一面，腾讯云二面，==百度一面==）

> ![TCP的拥塞控制（详解）7](https://res-static.hc-cdn.cn/fms/img/a7741d3223791e04828b06cf566a6bf71603441882876.png)
>
> 拥塞窗口（cwnd）与发送窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口
>
> - 慢开始与拥塞避免。
>   - 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...
>   - 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd \>= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1
>   - 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始
> - 快重传与快恢复
>   - 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M<sub>1</sub> 和 M<sub>2</sub>，此时收到 M<sub>4</sub>，应当发送对 M<sub>2</sub> 的确认。在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M<sub>2</sub>，则 M<sub>3</sub> 丢失，立即重传 M<sub>3</sub>。
>   - 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。
>   - 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

切分后乱序是怎么处理的呢？（腾讯CDG一面）

> [老铁意向+ 很多tcp的总结](https://www.nowcoder.com/discuss/530380?type=2&channel=-2&source_id=discuss_tag_discuss_hot)

一个消息报的长度在哪个地方会有限制？（腾讯CDG一面）

> 传输层

TCP还有其他拥塞机制吗（腾讯云二面）

#### 6.2 HTTP

HTTP和HTTPS的区别，对称加密和非对称加密，HTTPS的加密过程（华为Cloudbu一面，腾讯云一面，==腾讯CDG事务开发一面==，==Lazada一面==）

> [HTTPS 详解一：附带最精美详尽的 HTTPS 原理图](https://segmentfault.com/a/1190000021494676)
>
> 一、HTTP和HTTPS的区别
>
> > 1、**端口**：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认端口443
> >
> > 2、**安全性和资源消耗**：
> >
> > - HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务端都无法验证对方的身份。
> > - HTTPS是运行在SSL（安全套接层）/TLS（安全传输层协议）之上的HTTP协议，SSL/TLS运行在TCP之上，所有传输的内容都经过加密，加密采用对称加密，但对称加密的秘钥用服务器方的证书进行了非对称加密。
> > - 所以说，HTTP安全性没有HTTPS高，但是HTTPS比HTTP消耗更多服务器资源。
> >
> > 3、使用 HTTPS 协议需要申请 CA 证书，一般免费证书较少，因而需要一定费用。
>
> 二、对称加密与非对称加密
>
> > 1、对称加密。加密和解密都使用同一个密钥，常见的对称加密算法有 DES、3DES 和 AES
> >
> > - 优点：算法公开、计算量小、加密速度快、加密效率高，适合加密比较大的数据。
> > - 缺点：
> >   1. 交易双方需要使用相同的密钥，也就无法避免密钥的传输，而密钥在传输过程中无法保证不被截获，因此对称加密的安全性得不到保证。
> >   2. 每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一密钥，这会使得发收信双方所拥有的钥匙数量急剧增长，[密钥管理](https://link.segmentfault.com/?url=http%3A%2F%2Fbaike.baidu.com%2Fview%2F297229.htm)成为双方的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。
> >
> > 2、非对称加密。加密和解密需要使用两个不同的密钥：公钥（public key）和私钥（private key）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。
> >
> > - 优点：算法公开，加密和解密使用不同的钥匙，私钥不需要通过网络进行传输，安全性很高。
> > - 缺点：计算量比较大，加密和解密速度相比对称加密慢很多。
>
> 三、HTTPS的加密过程
>
> > ![preview](https://segmentfault.com/img/bVbClUl/view)
> >
> > 1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。
> > 2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。
> > 3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。
> > 4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。
> > 5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。
> > 6. 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。
> > 7. 服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。
> > 8. 双方使用对称加密愉快地传输所有数据。

HTTP常见的请求方法（华为Cloudbu一面）

> 一、常用的请求方法
>
> **GET** 获取资源；**HEAD** 获取报文首部；**POST** 传输实体主体；**PUT** 上传文件；**PATCH** 对资源进行部分修改；**DELETE** 删除文件；**OPTIONS** 查询支持的方法；**CONNECT** 要求在与代理服务器通信时建立隧道；**TRACE** 追踪路径
>
> 二、GET和POST的区别
>
> - GET请求参数通过URL传递，POST的参数放在请求体中。 
>
> - GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把请求头和请求体一并发送出去；而对于POST，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体。 
>
> - GET请求会被浏览器主动缓存，而POST不会，除非手动设置。 
>
> - GET请求只能进行url编码，而POST支持多种编码方式。 
>
> - GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。

HTTP的响应码有哪些（华为Cloudbu一面，腾讯CDG一面）

> ![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)
>
> -   **100 Continue**：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
>
> -   **200 OK**  
>
> -   **204 No Content**：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。
>
> 
>-   **301 Moved Permanently**：永久性重定向
> 
>-   **302 Found**：临时性重定向
> 
>
> -   **400 Bad Request**：请求报文中存在语法错误。
>
> -   **401 Unauthorized**：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
>
> -   **403 Forbidden**：请求被拒绝。
>
> -   **404 Not Found**  
>
> -   **500 Internal Server Error**：服务器正在执行请求时发生错误。
>-   **503 Service Unavailable**：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

HTTP消息的结构？（腾讯CDG一面）

> 请求报文结构：
> - 第一行是包含了请求方法、URL、协议版本；
> - 接下来的多行都是请求首部 Header，每个首部都有一个首部名称，以及对应的值。
> - 一个空行用来分隔首部和内容主体 Body
> - 最后是请求的内容主体
>
> 响应报文结构：
>
> - 第一行包含协议版本、状态码以及描述，最常见的是 200 OK 表示请求成功了
> - 接下来多行也是首部内容
> - 一个空行分隔首部和内容主体
> - 最后是响应的内容主体

gRPC和HTTP的区别（==华为公共开发一面==）

> [HTTP，TCP， socket，RPC 与gRPC都是啥？](https://www.jianshu.com/p/959030de7f1c)
>
> 一、HTTP, TCP, socket, RPC与gRPC的概念
>
> > - TCP是传输层协议，主要解决数据如何在网络中传输
> > - HTTP 是应用层协议，主要解决如何包装数据（文本信息），是建立在tcp协议之上的应用。
> > - TCP协议是以二进制数据流的形式解决传输层的事儿，但对上层的应用开发极不友好，所以面向应用层的开发又产生了HTTP协议。
> > - socket 是针对TCP或UDP的具体接口实现，提供了在传输层进行网络编程的方法。
> > - RPC跟HTTP不是对立面，RPC中可以使用HTTP作为通讯协议。**RPC是一种设计、实现框架，通讯协议只是其中一部分。**RPC需要解决的问题：
> >   - 建立通信：在客户端与服务端建立起数据传输通道，大都是TCP连接（gRPC使用了HTTP2）。
> >   - 寻址：A服务器上的应用需要告诉RPC框架：B服务器地址、端口，调用函数名称。所以必须实现待调用方法到call ID的映射。
> >   - 序列化与反序列化：由于网络协议都是二进制的，所以调用方法的参数在进行传递时首先要序列化成二进制，B服务器收到请求后要再对参数进行反序列化。恢复为内存中的表达方式，找到对应的方法进行本地调用，得到返回值。返回值从B到A的传输仍要经过序列化与反序列化的过程。
> > - gRPC是谷歌开源的一个 RPC 框架，面向移动和 HTTP/2 设计。
> >   - 内容交换格式采用ProtoBuf(Google Protocol Buffers)，开源已久，提供了一种灵活、高效、自动序列化结构数据的机制，作用与XML，Json类似，但使用二进制，（反）序列化速度快，压缩效率高。
> >   - 传输协议 采用http2，性能比http1.1好了很多
>
> 二、HTTP1.0和HTTP1.1的区别
>
> > - **长连接**：HTTP1.0默认使用短连接，每次请求都需要建立新的TCP连接，连接不能复用。HTTP1.1支持长连接，复用TCP连接。
> >
> > - **缓存处理**：在HTTP1.0中主要使用header里的`If-Modified-Since,Expires`来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。
> >
> > - **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如[客户端]()只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
> >
> > - **错误通知的管理**：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
> >
> > - **Host头处理**：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
>
> 三、HTTP1.1和HTTP2.0的区别
>
> > - **新的二进制格式**：HTTP 1.x的解析是基于文本，HTTP 2.0的解析采用二进制，实现方便，健壮性更好。
> > - **多路复用**。多个request共享一个连接。
> > - **header压缩**。在HTTP1.x中header信息很多，且每次都会重复发送，造成很大浪费。HTTP2.0使用encoder减少了传输的header大小，且通信双方都缓存一份包含了header信息的表，此后的请求可以只发送差异数据，避免信息的重复传输，进一步减少需要传输的内容大小。
> > - **服务端推送**。客户端在请求一个资源时，服务端会把相关资源一起发给客户端，这样客户端就不需要再次发起请求。

#### 其他

OSI的七层模型有哪些（华为Cloudbu一面，==字节系统研发一面==）

> ![五层体系结构](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E4%BA%94%E5%B1%82%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png)
>
> - 应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、SMTP协议等。
>
> - 表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
>
> - 会话层：负责在网络中的两节点之间建立、维持和终止通信，如服务器验证用户登录便是由会话层完成的。
>
> - 运输层：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。
>
> - 网络层：为主机提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。
>
> - 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。
>
> - 物理层：物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

输入域名到页面发生渲染会发生什么？DNS的解析过程？（今日头条一面，今日头条测开二面，==Lazada一面==）

> 输入域名到页面发生渲染会发生什么？
>
> 1. 对www.baidu.com这个网址进行DNS域名解析，得到对应的IP地址；
> 2. 根据这个IP，找到对应的服务器，发起TCP的三次握手；
> 3. 建立TCP连接后发起HTTP请求；
> 4. 服务器响应HTTP请求，浏览器得到html代码；
> 5. 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）；
> 6. 浏览器对页面进行渲染呈现给用户；
> 7. 服务器关闭TCP连接；
>
> DNS的解析过程？[面试：DNS解析过程和原理（7000字）](https://blog.csdn.net/weixin_44523860/article/details/110352555)
>
> 1. 浏览器搜索自己的DNS缓存 
>
> 2. 若没有，则搜索操作系统中的DNS缓存和hosts文件 
>
> 3. 若没有，则操作系统将域名发送至本地域名服务器，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向根域名服务器、顶级域名服务器、权限域名服务器发起查询请求，最终返回IP地址给本地域名服务器 
>
> 4. 本地域名服务器将得到的IP地址返回给操作系统，同时自己也将IP地址缓存起来 
>
> 5. 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来 
>
> 6. 浏览器得到域名对应的IP地址

应用层常用的端口？（腾讯CDG一面）

> |        应用        | 应用层协议 | 端口号  | 传输层协议 |            备注             |
> | :----------------: | :--------: | :-----: | :--------: | :-------------------------: |
> |      域名解析      |    DNS     |   53    |  UDP/TCP   | 长度超过 512 字节时使用 TCP |
> |  动态主机配置协议  |    DHCP    |  67/68  |    UDP     |                             |
> |  简单网络管理协议  |    SNMP    | 161/162 |    UDP     |                             |
> |    文件传送协议    |    FTP     |  20/21  |    TCP     |  控制连接 21，数据连接 20   |
> |    远程终端协议    |   TELNET   |   23    |    TCP     |                             |
> |   超文本传送协议   |    HTTP    |   80    |    TCP     |                             |
> | 超文本传输安全协议 |   HTTPS    |   443   |    TCP     |                             |
> |  简单邮件传送协议  |    SMTP    |   25    |    TCP     |                             |
> |    邮件读取协议    |    POP3    |   110   |    TCP     |                             |
> |  网际报文存取协议  |    IMAP    |   143   |    TCP     |                             |

网络常见的IO模型？select和poll（今日头条一面，今日头条测开二面，==腾讯CDG事务开发一面==，==百度一面==，==超参数一面==）

> 一、I/O模型
>
> 一个输入操作通常包括两个阶段：
>
> - 等待数据准备好
> - 从内核向进程复制数据
>
> 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。
>
> 1、阻塞式I/O
>
> 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。
>
> 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。
>
> 下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。
>
> ```
> ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
> ```
>
> [![img](https://camo.githubusercontent.com/68a3f48b4948ac53d220664a56429c5e84c0667ff640d6038c6e9dced48da9e1/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383431363831325f342e706e67)](https://camo.githubusercontent.com/68a3f48b4948ac53d220664a56429c5e84c0667ff640d6038c6e9dced48da9e1/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383431363831325f342e706e67)
>
> 2、非阻塞式I/O
>
> 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。
>
> 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。
>
> [![img](https://camo.githubusercontent.com/ecac1a2f263b198fa5660f7dd5a9accce515f49d6f7256a87fa1410049a1debe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393030303336315f352e706e67)](https://camo.githubusercontent.com/ecac1a2f263b198fa5660f7dd5a9accce515f49d6f7256a87fa1410049a1debe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393030303336315f352e706e67)
>
> 3、I/O复用
>
> 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。
>
> 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。
>
> 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。
>
> [![img](https://camo.githubusercontent.com/aa49b130631537882aa3d8338f3e8edd4136aca31ba5b8f84b7bd1c2a3049bc8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393434343831385f362e706e67)](https://camo.githubusercontent.com/aa49b130631537882aa3d8338f3e8edd4136aca31ba5b8f84b7bd1c2a3049bc8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393434343831385f362e706e67)
>
> 4、信号驱动I/O
>
> 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。
>
> 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。
>
> [![img](https://camo.githubusercontent.com/4ef6a2ee94e21ab9b8365a59a480fbbd44f375fd98da42873b5fcbb15530411e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393535333635315f372e706e67)](https://camo.githubusercontent.com/4ef6a2ee94e21ab9b8365a59a480fbbd44f375fd98da42873b5fcbb15530411e/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932393535333635315f372e706e67)
>
> 5、异步I/O
>
> 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。
>
> 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。
>
> [![img](https://camo.githubusercontent.com/4e523f16614b51e79c78bcf61234201ae4ca5b36b2bc4bb24572ee2622fe458c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323933303234333238365f382e706e67)](https://camo.githubusercontent.com/4e523f16614b51e79c78bcf61234201ae4ca5b36b2bc4bb24572ee2622fe458c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323933303234333238365f382e706e67)
>
> 6、五大I/O模型比较
>
> - 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
> - 异步 I/O：第二阶段应用进程不会阻塞。
>
> 同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。
>
> 非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。
>
> [![img](https://camo.githubusercontent.com/e5ec41f6e0278716f715bfbd28b9a401684f1373cc5d979b34da21d5a1c7f2ef/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383130353739315f332e706e67)](https://camo.githubusercontent.com/e5ec41f6e0278716f715bfbd28b9a401684f1373cc5d979b34da21d5a1c7f2ef/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f313439323932383130353739315f332e706e67)
>
> 二、I/O复用
>
> 1、select
>
> ```c
> int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
> ```
>
> select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。
>
> - fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。
> - timeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。
> - 成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。
>
> 2、poll
>
> ```c
> int poll(struct pollfd *fds, unsigned int nfds, int timeout);
> ```
>
> poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。
>
> poll 中的描述符是 pollfd 类型的数组，pollfd 的定义如下：
>
> ```c
> struct pollfd {
> int   fd;         /* file descriptor */
> short events;     /* requested events */
> short revents;    /* returned events */
> };
> ```
>
> 3、比较
>
> select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。
>
> - select 会修改描述符，而 poll 不会；
> - select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
> - poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
> - 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。
>
> select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。
>
> 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。
>
> 4、epoll
>
> ```
> int epoll_create(int size);
> int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
> int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
> ```
>
> epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。
>
> 从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
>
> epoll 仅适用于 Linux OS。
>
> epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
>
> epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。
>
> 工作模式
>
> - **LT模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
> - **ET模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。
>
> 5、应用场景
>
> select应用场景
>
> - select 的 timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。
> - select 可移植性更好，几乎被所有主流平台所支持。
>
> poll应用场景
>
> - poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。
>
> epoll应用场景
>
> - 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。
> - 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。
> - 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。

### 七、操作系统

#### 7.1 基础

线程和进程的区别？(今日头条一面，==字节系统研发一面==)

> - 拥有资源。进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问所属进程的资源。
> - 调度。线程是独立调度的基本单位，在同一进程中线程之间的上下文切换不会带来进程之间的上下文切换
> - 系统开销。线程之间的上下文切换的开销远小于进程
> - 通信方面。同一进程的线程通过读取数据进行通信，但是进程通信需要借助 IPC
>
> 进程切换的过程：
>
> 1. 保存处理机上下文，包括程序计数器和其他寄存器。
> 2. 更新PCB信息。
> 3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
> 4. 选择另一个进程执行，并更新其PCB。
> 5. 更新内存管理的数据结构。
> 6. 恢复处理机上下文。

线程和进程拥有哪些资源（==字节系统研发一面==）

> ![img](https://oscimg.oschina.net/oscnet/up-cd8ac705f6f004c01e0a1312f1599430ba5.png)

线程之间的同步机制（==字节系统研发一面==，==华为公共开发一面==）

> 1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
> 2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
> 3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

多个进程之间通讯的方式？管道具体指的是什么？什么场景下会用到管道？(今日头条一面，腾讯CDG一面，今日头条测开二面)

> - **管道/匿名管道(Pipes)** 
>   - 用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
> - **有名管道(Names Pipes)** :
>   - 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。
>   - 有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
> - **信号(Signal)** 
>   - 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
> - **消息队列(Message Queuing)** 
>   - 消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。
>   - 管道和消息队列的通信数据都是先进先出的原则。
>   - 与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
>   - 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。
>   - **消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。**
> - **信号量(Semaphores)** 
>   - 信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。
>   - 这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
> - **共享内存(Shared memory)** 
>   - 使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新
>   - 这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
> - **套接字(Sockets)** :
>   - 此方法主要用于在客户端和服务器之间通过网络进行通信。
>   - 套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

进程切换操作系统会做什么（腾讯云一面）

操作系统的调度算法（腾讯云一面）

> - **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
> - **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
> - **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
> - **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。
> - **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

逻辑地址（虚拟地址)、物理地址、分段、分页（==字节系统研发一面==）

> 一、连续分配管理方式和非连续分配管理方式
>
> - 连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理**；
> - 非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。
>
> 二、常见的内存管理机制
>
> - **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
> - **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
> - **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
> - **段页式管理机制** ：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。
>
> 三、分段和分页的共同点和区别
>
> 1、共同点：
>
> - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
> - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
>
> 2、区别：
>
> - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
> - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。
>
> 四、逻辑地址（虚拟地址)与物理地址
>
> - C语言指针存储的地址就是一个逻辑地址，由操作系统决定；
> - 物理地址指的是真实物理内存中的地址，是内存地址寄存器的地址
>
> 五、为什么要有虚拟地址空间
>
> 没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？
>
> - 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
> - 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。
>
> 通过虚拟地址访问内存有以下优势：
>
> - 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
> - 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。
> - 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

内存的命名映射（==字节系统研发一面==）

操作系统如何申请一块内存（腾讯云一面）

> 检查当前内存空间是否具有足够的空间，如果有则进行申请，并将逻辑地址与物理地址的映射写入页表；
>
> 若没有则触发缺页中断，使用缺页中断算法将当前内存中的页面进行移除，再进行申请

#### 7.2 Linux

linux的目录都是什么含义（华为Cloudbu一面）

> 为了使不同的Linux发布版本的目录结构保持一致性，FHS规定了Linux的目录结构。最基础的三个目录如下：
>
> - /（root，根目录）
> - /usr（unix software resource）：系统默认软件都会安装到这个目录
> - /var（variable）：存放系统或程序运行过程中的数据文件
>
> <div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/linux-filesystem.png" width=""/> </div><br>

linux下软链接和硬链接的区别？(今日头条一面)

> - 实体链接（硬链接）
>   - 在目录下创建一个条目，记录文件名与inode编号，这个inode就是源文件的inode；
>   - 删除任意一个条目，文件还是存在，只要引用数量不为0。
>   - 限制
>     - 不能跨越文件系统、不能对目录进行链接
>
> - 符号链接（软链接）
>   - 符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为Windows的快捷方式；
>   - 当源文件被删除了，链接文件就打不开了；
>   - 因为记录的是路径，所以可以为目录简历符号链接

linux系统加载程序并运行的过程？(今日头条一面)

> [程序的编译、链接、装载与运行](https://www.nosuchfield.com/2018/11/23/Program-compilation-linking-loading-and-running/)
>
> ![img](https://www.nosuchfield.com/images/20181123/main.png)
>
> - 编译
>   - 将程序员所写的高级语言代码转化为对应的目标文件的过程。一般来说高级语言的编译要经过预处理、编译和汇编这几个过程
>   - 预处理
>   - 编译
>     - 对预处理之后的文本进行词法分析、语法分析、语义分析并优化后生成响应的汇编文件
>   - 汇编
>     - 将汇编代码转化为机器指令，生成目标文件
>     - 目标文件的结构与可执行文件是一致的，它们之间只存在一些细微的差异
>     - 目标文件是无法被执行的，它还需要链接这一步操作，目标文件被链接之后才可以产生可执行文件
> - 目标文件的格式
>   - Linux下的目标文件的格式叫做ELF（Executable Linkable Format），ELF header保存如下的内容：
>     - ELF的magic number
>     - 文件机器字节长度
>     - ELF版本
>     - 操作系统平台
>     - 硬件平台
>     - 程序的入口地址
>     - 段表的位置和长度。可以从ELF文件中获取到段表（Section Header Table）
>     - 段的数量
> - （静态）链接
>   - 与动态链接的比较
>     - 动态链接对内存和磁盘的节省十分有限
>     - 不需要考虑动态链接库的不同的版本，静态链接的文件可以做到链接即可执行，减少了运维和部署上的复杂度
>     - 在有些新发明的语言（例如golang）中链接过程中已经开始开始使用静态链接
>   - 静态链接的过程
>     - 扫面所有的目标文件，获取它们的每个段的长度、位置和属性，并将每个目标文件中的符号表的符号定义和符号引用收集起来放在一个全局符号表中，建立起可执行文件到目标文件的段映射关系
>     - 读取目标文件中的段时间，并解析符号表信息，根据符号表信息进行重定位、调整代码中的地址等操作
> - 装载
> - 运行
>   - 操作系统在创建进程之后，jmp到这个进程的入口函数
>   - 入口函数对程序运行环境进行初始化，包括堆、I/O、线程、全局变量的构造等等
>   - 入口函数在完成初始化之后，调用main函数，开始执行程序的主体
>   - main函数执行完毕之后返回到入口函数，入口函数进行清理工作，最后通过系统调用结束进程

Linux上常用到的一些命令（华为Cloudbu一面，腾讯CDG一面，深信服一面）

> - ls。列出文件或者目录信息
> - cd。更换当前目录
> - mkdir。创建目录
> - rmdir。删除目录，目录必须为空。
> - cp。复制文件
> - rm。删除文件
> - mv。移动文件
> - cat。获取文件内容
> - ps。查看某个时间点的进程信息
> - top。实时显示进程信息
> - kill。杀死进程
> - chmod。用于控制用户对文件的权限
> - netstat。用于显示各种网络相关信息，如网络连接，路由表，接口状态（Interface Statistics），masquerade连接，多播成员（Multicast Memberships）等

chmod命令的用法，777是什么含义（华为Cloudbu一面，==腾讯CDG事务开发一面==）

> 全称change mode，用于控制用户对文件的权限的命令
>
> linux的权限有：
>
> - r：4，读
> - w：2， 写
> - x：1，执行
>
> 777表示三种不同的对象,即文件所有人，文件所有组，和其他人。

如何查询进程和线程的ID？（淘宝一面，==腾讯CDG事务开发一面==）

> - 查看进程ID的方式
>   - ps
> - 查看线程ID的方式
>   - ps -T -p <pid>。
>   - Top -H -p <pid>。
>   - htop

### 八、中间件

数据的分类（今日头条测开二面）

非关系型数据库有哪些（今日头条测开二面）

> [非关系型数据库有哪些](https://www.huaweicloud.com/zhishi/db21.html)
>
> - 文档数据库——这些数据库通常将每个键与称为文档的复杂数据结构配对。文档可以包含键数组对、键值对甚至嵌套文档。包括：
>   - MongoDB等
> - 键值存储——每个单独的项都存储为键值对。键值存储是所有NoSQL数据库中最简单的数据库
>   - Redis、Memcached等
> - 宽列存储——这些类型的数据库针对大型数据集上的查询进行了优化，它们将数据列存储在一起，而不是行
>   - Cassandra、Hbase等
> - 图形存储——这些存储关于图形、网络的信息，例如社会关系、路线图、交通链接
>   - Neo4j、AllegroGraph

#### 8.1 MySQL

MySQL的索引（淘宝一面，腾讯云二面，==腾讯TEG应用开发一面==，==超参数一面==）

> [MySQL索引-JavaGuide](https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95)
>
> 一、何为索引？有什么作用
>
> 索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash。
>
> 索引的作用就相当于目录的作用。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。
>
> 二、索引的优缺点
>
> 1、优点：
>
> - 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。
> - 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
>
> 2、缺点：
>
> - 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
> - 索引需要使用物理文件存储，也会耗费一定空间。
>
> 三、索引的底层数据结构
>
> 1、为什么选择B+树不选择Hash表
>
> - Hash 冲突问题 ：我们上面也提到过Hash 冲突了，不过对于数据库来说这还不算最大的缺点。
>
> - Hash 索引不支持顺序和范围查询(Hash 索引不支持顺序和范围查询
>
> 2、B树和B+树的区别
>
> - B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
> - B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
> - B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。
>
> 3、MyISAM索引的底层结构
>
> - B+Tree 叶节点的 data 域存放的是数据记录的地址
> - 在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录
> - 这被称为“非聚簇索引”
>
> 4、InnoDB索引的底层结构
>
> - InnoDB 引擎中，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录
> - 这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引，这被称为“聚簇索引（或聚集索引）”
> - 其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址
> - 在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引
> - 在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂
>
> 5、B+树为什么适合磁盘存储
>
> [B+树在磁盘存储中的应用](https://www.cnblogs.com/nullzx/p/8978177.html)
>
> - 主存和磁盘之间的数据交换不是以字节为单位的，而是以n个扇区为单位的（一个扇区有512字节）
> - 假设，我们现在选择4KB作为内存和磁盘之间的传输单位，那么我们在设计B+树的时候，不论是索引结点还是叶子结点都使用4KB作为结点的大小
> - 快速的原因是，索引结点中不存数据，只存键和指针，所以一个索引结点就可以存储大量的分支，而一个索引结点只需要一次IO即可读取到内存中。
>
> 四、主键索引与辅助索引
>
> 1、主键索引。数据表的主键列使用的就是主键索引
>
> 2、二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。
>
> - 唯一索引(Unique Key) ：唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
> - 普通索引(Index) ：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。
> - 前缀索引(Prefix)：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
> - 全文索引(Full Text) ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。
>
> 五、聚集索引和非聚集索引
>
> 1、聚集索引
>
> 聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。
>
> 优点
>
> - 聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。
>
> 缺点
>
> - 依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。
>
> - 更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。
>
> 2、非聚集索引
>
> 非聚集索引即索引结构和数据分开存放的索引
>
> 优点
>
> - 更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的
>
> 缺点
>
> - 跟聚集索引一样，非聚集索引也依赖于有序的数据
> - 可能会二次查询(回表):这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。
>
> 六、覆盖索引
>
> 覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。
>
> - 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。
>
> - 再如普通索引，如果一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表。
>
> 七、创建索引的注意事项
>
> 1、选择合适的字段创建索引
>
> - 不为 NULL 的字段 ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。
> - 被频繁查询的字段 ：我们创建索引的字段应该是查询操作非常频繁的字段。
> - 被作为条件查询的字段 ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。
> - 频繁需要排序的字段：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
> - 被经常频繁用于连接的字段：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。
>
> 2、被频繁更新的字段应该慎重建立索引
>
> 虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。
>
> 3、尽可能地考虑建立联合索引而不是单列索引
>
> 因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。
>
> 4、注意避免冗余索引
>
> 冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。
>
> 5、考虑在字符串类型地字段上使用前缀索引代替普通索引
>
> 前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。
>
> 七、使用索引的一些建议
>
> - 对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引
> - 避免 where 子句中对字段施加函数，这会造成无法命中索引。
> - 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。
> - 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗
> - 在使用 limit offset 查询缓慢时，可以借助索引来提高性能

MyIASM和InnoDB的区别（==百度一面==）

> - MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
>
> - MyISAM 不提供事务支持。InnoDB 提供事务支持，具有提交(commit)和回滚(rollback)事务的能力。
> - MyISAM 不支持外键，而 InnoDB 支持。
> - MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 。
> - MyISAM 不支持MVCC，而 InnoDB 支持MVCC。

InnoDB事务的四大隔离级别（腾讯云一面，==百度一面==）

> 一、ACID特性
>
> 1. 原子性（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
> 2. 一致性（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
> 3. 隔离性（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
> 4. 持久性（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
>
> 二、数据事务的实现原理
>
> MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。
>
> MySQL InnoDB 引擎通过 **锁机制**、**MVCC** 等手段来保证事务的隔离性（ 默认支持的隔离级别是 **`REPEATABLE-READ`** ）。
>
> 保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。
>
> 三、并发事务带来哪些问题
>
> - 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
> - 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。
> - 不可重复读（Unrepeatable read）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
> - 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
>
> 四、事务的隔离级别
>
> - READ-UNCOMMITTED(读取未提交)：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
> - READ-COMMITTED(读取已提交)：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
> - REPEATABLE-READ(可重复读)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
> - SERIALIZABLE(可串行化)：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 
>
> MySQL InnoDB 的 REPEATABLE-READ（可重读）并不保证避免幻读，需要应用使用加锁读来保证。而这个加锁度使用到的机制就是 Next-Key Locks。
>
> [MySQL的多版本并发控制(MVCC)是什么？](https://segmentfault.com/a/1190000037557620)

MySQL的锁（腾讯云一面，==腾讯CDG事务开发一面==）

> Record lock行锁
>
> - 单个行记录上的锁
>
> Gap lock间隙锁
>
> - 锁定一个范围，不包括记录本身
> - 间隙锁的目的是为了阻止多个事务将记录插入同一范围内，这样会导致幻读
>
> Next-key
>
> - 行锁+间隙锁 锁定一个范围，包含记录本身

数据库中乐观锁和悲观锁。数据库中的悲观锁的语法。（腾讯CDG一面）

> [MySQL/InnoDB中，乐观锁、悲观锁、共享锁、排它锁、行锁、表锁、死锁概念的理解](https://segmentfault.com/a/1190000015815061)
>
> 一、乐观锁
>
> - 用数据版本(version)记录机制实现
>
> - 为数据增加一个版本共识，一般是通过为数据库表增加一个数据类型的“version”字段来实现
>
> - 当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加1.
>
> - 当提交更新的时候，判断数据表对应记录的当前版本信息与第一次取出来的version值进行对比
>
>   - 如果数据库表当前版本号与第一次取出来的version值相等，则更新，否则认为是过期数据
>
> - 数据库表设计
>
>   - 三个字段分别是id, value, version
>   - `select id,value,version from TABLE where id=#{id}`
>
> - 每次更新表中的value字段时，为了防止冲突，需要这样操作
>
>   ```
>   update TABLE
>   set value=2,version=version+1
>   where id=#{id} and version=#{version};
>   ```
>
> 二、悲观锁
>
> - 悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作
> - 共享锁与排它锁时悲观锁的两种不同实现
> - 要使用悲观锁，我们必须关闭MySQL数据库的自动提交属性
>
> ```mysql
> set autocommit=0;
> # 设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：
> # 1. 开始事务
> begin;/begin work;/start transaction; (三者选一就可以)
> # 2. 查询表信息
> select status from TABLE where id=1 for update;
> # 3. 插入一条数据
> insert into TABLE (id,value) values (2,2);
> # 4. 修改数据为
> update TABLE set value=2 where id=1;
> # 5. 提交事务
> commit;/commit work;
> ```

后端如何优化数据库性能？（淘宝一面，==百度一面==）

> 一、使用Explain进行分析
> - Explain用来分析SELECT查询语句，开发人员可以通过Explain结果来优化查询语句
> - 比较重要的字段：
>   - select_type：查询类型，有简单查询、联合查询、子查询等
>   - key：使用的索引
>   - rows：扫描的行数
>
> 二、优化数据访问
> - 减少请求的数据量
>   - 只返回必要的列：最好不要使用SELECT *语句
>   - 只返回必要的行：使用LIMIT语句来限制返回的数据。
>   - 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。
> - 减少服务端扫描的行数
>   - 最有效的方法是使用索引来覆盖查询
>
> 三、重构查询方式
> - 切分大查询
>   - 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。
> - 分解大连接查询
>   - 将一个大连接查询分解成对每一个表进行一次单表查询，然后再应用程序中关联。这样做的好处有：
>     - 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
>     - 减少锁竞争；
>     - 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
>     - 查询本身效率也可能会有所提升。

主从分离中主服务器和从服务器如何同步？MySQL的分布式（淘宝一面，==Lazada二面==，==超参数一面==）

> 一、主从复制
>
> 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。
>
> -   **binlog 线程**  ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。
> -   **I/O 线程**  ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。
> -   **SQL 线程**  ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。
>
> <div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/master-slave.png" width=""> </div><br>
>
> 二、读写分离
>
> 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。
>
> 读写分离能提高性能的原因在于：
>
> - 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
> - 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
> - 增加冗余，提高可用性。
>
> 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。
>
> ![img](https://camo.githubusercontent.com/7f9279aeb3dd23a8a0a64895594bd76ac9fce2dfb6bc24974a07cc83888c6fc9/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f6d61737465722d736c6176652d70726f78792e706e67)

MySQL语法（腾讯CDG一面，==腾讯CDG事务开发一面==，==百度一面==）

> [一千行 MySQL 学习笔记](https://snailclimb.gitee.io/javaguide/#/docs/database/mysql/一千行MySQL学习笔记)
>
> 事务（腾讯CDG一面）
>
> ```mysql
> -- 事务开启
>     START TRANSACTION; 或者 BEGIN;
>     开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。
> -- 事务提交
>     COMMIT;
> -- 事务回滚
>     ROLLBACK;
>     如果部分操作发生问题，映射到事务开启前。
> ```
>
> SELECT（腾讯CDG一面）
>
> ```mysql
> /* SELECT */ ------------------
> SELECT [ALL|DISTINCT] select_expr FROM -> WHERE -> GROUP BY [合计函数] -> HAVING -> ORDER BY -> LIMIT
> a. select_expr
>     -- 可以用 * 表示所有字段。
>         select * from tb;
>     -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）
>         select stu, 29+25, now() from tb;
>     -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。
>         - 使用 as 关键字，也可省略 as.
>         select stu+10 as add10 from tb;
> b. FROM 子句
>     用于标识查询来源。
>     -- 可以为表起别名。使用as关键字。
>         SELECT * FROM tb1 AS tt, tb2 AS bb;
>     -- from子句后，可以同时出现多个表。
>         -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。
>         SELECT * FROM tb1, tb2;
>     -- 向优化符提示如何选择索引
>         USE INDEX、IGNORE INDEX、FORCE INDEX
>         SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;
>         SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;
> c. WHERE 子句
>     -- 从from获得的数据源中进行筛选。
>     -- 整型1表示真，0表示假。
>     -- 表达式由运算符和运算数组成。
>         -- 运算数：变量（字段）、值、函数返回值
>         -- 运算符：
>             =, <=>, <>, !=, <=, <, >=, >, !, &&, ||,
>             in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor
>             is/is not 加上ture/false/unknown，检验某个值的真假
>             <=>与<>功能相同，<=>可用于null比较
> d. GROUP BY 子句, 分组子句
>     GROUP BY 字段/别名 [排序方式]
>     分组后会进行排序。升序：ASC，降序：DESC
>     以下[合计函数]需配合 GROUP BY 使用：
>     count 返回不同的非NULL值数目  count(*)、count(字段)
>     sum 求和
>     max 求最大值
>     min 求最小值
>     avg 求平均值
>     group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。
> e. HAVING 子句，条件子句
>     与 where 功能、用法相同，执行时机不同。
>     where 在开始时执行检测数据，对原数据进行过滤。
>     having 对筛选出的结果再次进行过滤。
>     having 字段必须是查询出来的，where 字段必须是数据表存在的。
>     where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。
>     where 不可以使用合计函数。一般需用合计函数才会用 having
>     SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。
> f. ORDER BY 子句，排序子句
>     order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...
>     升序：ASC，降序：DESC
>     支持多个字段的排序。
> g. LIMIT 子句，限制结果数量子句
>     仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。
>     limit 起始位置, 获取条数
>     省略第一个参数，表示从索引0开始。limit 获取条数
> h. DISTINCT, ALL 选项
>     distinct 去除重复记录
>     默认为 all, 全部记录
> ```
>
> 连接查询（==百度一面==）
>
> ```mysql
> /* 连接查询(join) */ ------------------
>     将多个表的字段进行连接，可以指定连接条件。
> -- 内连接(inner join)
>     - 默认就是内连接，可省略inner。
>     - 只有数据存在时才能发送连接。即连接结果不能出现空行。
>     on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真）
>     也可用where表示连接条件。
>     还有 using, 但需字段名相同。 using(字段名)
>     -- 交叉连接 cross join
>         即，没有条件的内连接。
>         select * from tb1 cross join tb2;
> -- 外连接(outer join)
>     - 如果数据不存在，也会出现在连接结果中。
>     -- 左外连接 left join
>         如果数据不存在，左表记录会出现，而右表为null填充
>     -- 右外连接 right join
>         如果数据不存在，右表记录会出现，而左表为null填充
> -- 自然连接(natural join)
>     自动判断连接条件完成连接。
>     相当于省略了using，会自动查找相同字段名。
>     natural join
>     natural left join
>     natural right join
> select info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;
> ```
>
> UNION（==百度一面==）
>
> ```mysql
> /* UNION */ ------------------
>     将多个select查询的结果组合成一个结果集合。
>     SELECT ... UNION [ALL|DISTINCT] SELECT ...
>     默认 DISTINCT 方式，即所有返回的行都是唯一的
>     建议，对每个SELECT查询加上小括号包裹。
>     ORDER BY 排序时，需加上 LIMIT 进行结合。
>     需要各select查询的字段数量一样。
>     每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。
> ```
>
> 锁表（==腾讯CDG事务开发一面==）
>
> ```mysql
> /* 锁表 */
> 表锁定只用于防止其它客户端进行不正当地读取和写入
> MyISAM 支持表锁，InnoDB 支持行锁
> -- 锁定
>     LOCK TABLES tbl_name [AS alias]
> -- 解锁
>     UNLOCK TABLES
> ```

#### 8.2 Redis

Redis为什么那么快？（淘宝一面，腾讯云二面，==腾讯CDG事务开发一面==）

> [一文搞懂 Redis 高性能之 IO 多路复用](https://xie.infoq.cn/article/b3816e9fe3ac77684b4f29348)
>
> 1. Redis完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速
> 2. 数据结构简单，对数据的操作也简单；
> 3. 采用单线程，避免了不必要的上下文切换和竞争条件；
> 4. 使用多路复用IO模型，不在IO上浪费时间

Redis和Memcache的区别（今日头条测开二面）

> 一、共同点
>
> 1. 都是基于内存的数据库，一般都用来当做缓存使用。
> 2. 都有过期策略。
> 3. 两者的性能都非常高。
>
> 二、区别
>
> 1. Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
> 2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。
> 3. Redis 有灾难恢复机制。因为可以把缓存中的数据持久化到磁盘上。
> 4. Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
> 5. Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。
> 6. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。（Redis 6.0 引入了多线程 IO ）
> 7. Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
> 8. Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。

Redis用到哪些命令（腾讯TEG一面）

Redis有哪些数据结构？（淘宝一面，今日头条测开二面）

> - STRING 字符串
> - LIST 列表
> - SET 无序集合
> - HASH 包含键值对的无序散列表
> - ZSET 有序集合

有序集合有了解嘛？跳表数据结构有了解嘛？（淘宝一面）

> 跳跃表是有序集合的底层实现之一。
>
> 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。
>
> 在查找时，从上层指针开始查找，找到对应区间之后再到下一层去查找。
>
> 与红黑树灯平衡树相比，跳跃表具有以下优点：
>
> - 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性
> - 更容易实现
> - 支持无锁操作
>
> 跳跃表每个节点的结构
>
> ```c
> struct zslnode{
>     string value;
>     double score;
>     zslnode*[] forwards;	// 多层连接指针
>     zslnode*[] backward;	//回溯指针
> }
> ```

从zset删除数据的时间复杂度（腾讯云二面）

> [有序集(Sorted Set)](https://redis.readthedocs.io/en/2.4/sorted_set.html)
>
> - 查找任意数据的时间复杂度O(logN)
>
> - 插入数据的时间复杂度O(logN)
>
> - 跳表的删除O(logN)

Redis中AOF和RDB有什么区别？哪种方法更优？（淘宝一面，==腾讯CDG事务开发一面==）

> - RDB是一次全量备份，AOF日志是连续的增量备份；
> - 存储。RDB是内存数据的二进制序列化形式，而AOF日志记录的是修改内存数据的指令；
> - 数据丢失。RDB往往会造成一定时间的数据丢失
> - 恢复速度。RDB快照恢复速度非常快，而AOF由于需要处理巨大的写入会影响Redis性能

Redis的分布式（==Lazada一面==）

> 一、CAP理论
>
> - **C** - **C**onsistent ，一致性
> - **A** - **A**vailability ，可用性
> - **P** - **P**artition tolerance ，分区容忍性
>
> 分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的，这意味着必然会有网络断开的风险，这个网络断开的场景的专业词汇叫着「**网络分区**」。
>
> 在网络分区发生时，两个分布式节点之间无法进行通信，我们对一个节点进行的修改操作将无法同步到另外一个节点，所以数据的「一致性」将无法满足，因为两个分布式节点的数据不再保持一致。除非我们牺牲「可用性」，也就是暂停分布式节点服务，在网络分区发生时，不再提供修改数据的功能，直到网络状况完全恢复正常再继续对外提供服务。
>
> 2、最终一致
>
> Redis 的主从数据是异步同步的，所以分布式的 Redis 系统并不满足「**一致性**」要求。
>
> 当客户端在 Redis 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节点依旧可以正常对外提供修改服务，所以 Redis 满足「**可用性**」。
>
> Redis 保证「**最终一致性**」，从节点会努力追赶主节点，最终从节点的状态会和主节点的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。
>
> 3、主从同步
>
> 类似于RDB快照和AOF

#### 8.3 ElasticSearch

为什么要使用ES，MySQL索引和ES倒排索引的区别，ES的分词（深信服一面，腾讯TEG一面，==Lazada一面==，==Lazada二面==）

> [大白话告诉你倒排索引是个啥](https://zhuanlan.zhihu.com/p/112136054)
>
> 一、正排索引
>
> 正排索引就是数据库表，他通过id和数据进行关联。
>
> 我们可以通过搜索id，来获得相应的数据，也能删除数据。你买了一本书，书的目录其实也是正排搜索。
>
> 假设现在我要搜`苹果`俩字，那么他会对这张表格中每一行的数据做匹配，去查找一下，是否包含`苹果`这两个字，从第一条匹配到最后一条，如果一张表中数据量不多，几万，十几万，那么问题不大，但是一旦数据量有上百万，上千万，那么全表扫描这种的搜索性能就会有影响。
>
> - 优点：使用起来方便，原理也简单，比较入门
>
> - 缺点：检索效率低下，适合简单场景使用，比如传统项目，数据量较小的项目。不支持分词搜索。
>
> 二、倒排索引
>
> 倒排索引会把文档内容进行分词，比如`苹果公司发布iPhone`是一个文档数据，当我们把他存入到搜索引擎中去的时候，会有一个文档id，这个文档id就类似于数据库主键。但是这文档存储的时候和数据库不一样，他会进行一个分词，每一个词汇都会和文档id关联起来，可以根据词汇来找到所有出现的id列表
>
> - 优点：搜索更快，耗时短，用户体验高，精装度也高
>
> - 缺点：维护成本高，索引新建后要修改，必须先删除，前期需要很好地规划
>
> 三、分词
>
> 将文本转换为一系列单词的过程，也可以叫文本分析

ES的分布式特性（==Lazada一面==）

> - 将文档分区到不同的分片(shards)中，它们可以存在于一个或多个节点中；
> - 将分片均匀地分配到各个节点，对索引和搜索做负载均衡；
> - 冗余每一个分片，防止硬件故障造成数据丢失；
> - 将集群中任意一个节点（协调节点）上的请求路由到相应数据所在的节点；
> - 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移；

#### 8.4 Kafka

kafka的使用场景（今日头条测开二面，==百度一面==）

> [典型应用场景](https://support.huaweicloud.com/productdesc-kafka/kafka-scenarios.html)
>
> - 异步通信
> - 错峰流控与流量削峰
> - 日志同步

MQ发送消息的模式？（腾讯CDG一面）

> - 点对点模式。（一对一，消费者主动拉取数据，消息收到后消息清除）
> - 发布/订阅模式。（一对多，消费者消费数据之后不会清除消息）

MQ丢包怎么处理？（腾讯CDG一面，==百度一面==）

> 一、生产者丢失消息的情况
>
> 生产者(Producer) 调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。
>
> 所以，我们不能默认在调用`send`方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 `send` 方法发送消息实际上是异步的操作，我们可以通过 `get()`方法获取调用结果，但是这样也让它变为了同步操作。如果消息发送失败的话，我们检查失败的原因之后重新发送即可！
>
> 二、消费者丢失消息的情况
> 
> 我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。
> 
>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。
> 
>解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。
> 
>三、Kafka弄丢消息的情况
> 
>我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。
> 
>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。
> 
>1、**设置 acks = all**
> 
>解决办法就是我们设置 **acks = all**。acks 是 Kafka 生产者(Producer) 很重要的一个参数。
> 
>acks 的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。当我们配置 **acks = all** 代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。
> 
>2、**设置 replication.factor >= 3**
> 
>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 **replication.factor >= 3**。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。
> 
>3、**设置 min.insync.replicas > 1**
> 
>一般情况下我们还需要设置 **min.insync.replicas> 1** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。**min.insync.replicas** 的默认值为 1 ，在实际生产中应尽量避免默认值 1。
> 
>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 **replication.factor > min.insync.replicas** 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **replication.factor = min.insync.replicas + 1**。
> 
>4、**设置 unclean.leader.election.enable = false**
> 
>> **Kafka 0.11.0.0版本开始 unclean.leader.election.enable 参数的默认值由原来的true 改为false**
> 
>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 **unclean.leader.election.enable = false** 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。

Kafka如何搭建生产者和消费者（==腾讯CDG事务开发一面==）

Kafka的零拷贝（==百度一面==）

> [图解Kafka的零拷贝技术到底有多牛？](https://cloud.tencent.com/developer/article/1421266)
>
> - DMA，全称叫Direct Memory Access，一种可让某些硬件子系统去直接访问系统主内存，而不用依赖CPU的计算机系统的功能
>
> - 有了DMA后，就可以实现绝对的零拷贝了，因为网卡是直接去访问系统主内存的

消费者组（==腾讯CDG事务开发一面==）

> [怎么理解 Kafka 消费者与消费组之间的关系?](https://segmentfault.com/a/1190000039125247)
>
> - 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。
> - 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

Kafka的分布式（==Lazada一面==，==百度一面==）

> ![Kafka Topic Partition](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/KafkaTopicPartitioning.png)
>
> 比较重要的几个概念
>
> 1. **Producer（生产者）** : 产生消息的一方。
> 2. **Consumer（消费者）** : 消费消息的一方。
> 3. **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。
>
> 每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念：
>
> - **Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
> - **Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。
> - **Replica（副本）**：分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。
>
> **Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**
>
> 1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
> 2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

### 九、Spring

Spring框架的IoC容器？（华为Cloudbu一面，淘宝一面）

> - IOC容器具有依赖注入的功能，它可以创建对象，IOC负责实例化、定位、配置应用程序中对象及建立这些对象之间的依赖。
> - 通常new一个实例，控制权由程序员控制，而“控制反转”是指new实例的工作不由程序员来做而是交给spring容器来做

Spring注入有哪些方式？怎么将依赖建立起来？（华为Cloudbu一面，淘宝一面）

> - 基于构造函数的依赖注入。当容器调用带有一组参数的类构造函数时，基于构造函数的DI就完成了，其中每个参数代表一个对其他类的依赖。
> - 基于设置函数setter的依赖注入。当容器调用一个无参的构造函数或一个无参的静态factory方法来初始化bean后，通过容器在bean上调用setter函数，基于setter函数的依赖注入就完成了。
> - 基于注解的依赖注入。使用相关类，方法或者字段声明的注解，将bean配置移动到组件类本身。

Spring中AOP的实现？面向接口、面向类是怎么实现的？（华为Cloudbu一面，淘宝一面，阿里3一面，==Lazada二面==）

> AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。
>
> - 委托类
>   - 需要在实现类上加上`@Aspect`的注解，还需要通过`@Pointcut`注解来申明"切点"，即委托类和委托方法的路径
>   - 有了这些信息就足够获取委托类了。这里充分用到Java反射，先找到包含`@Aspect`注解的类，然后找到该类下的`@Pointcut`注解，读取所定义的委托类和委托方法注解，就完全能拿到委托类对象
> - 代理类
>   - 因为我们使用的是动态代理，这里的代理类可以被替换成`代理方法`。同样，我们在`@Aspect`注解的类中，用`@Around` `@Before` `@After`修饰的方法，就是我们想要的代理方法。
> - 总结
>   - 我们可以通过`BeanFactoryPostProcessor`的实现类，完成对所有`BeanDefinition`的扫描，找出我们定义的所有的切面类，然后循环里面的方法，找到切点、以及所有的通知方法，然后根据注解判断通知类型（也就是前置，后置还是环绕），最后解析切点的内容，扫描出所有的目标类。这样就获取了`委托类` 和 `代理方法`。
>   - 现在`委托类` 和 `代理方法` 都有了，我们知道在动态代理模式中，最终的目的是将委托类的方法执行，替换成代理类的方法执行。但是在Spring中，我们是感知不到`代理类`的，我们在代码中还是调用原`委托类`的方法，那么Spring框架是如何神不知鬼不觉地将`委托类`替换成`代理类`的呢？
>   - 在Bean的生命周期中，Bean在初始化前后会执行`BeanPostProcessor`的方法。可以把它理解成一个增强方法，可以将原始的Bean经过“增强”处理后加载到Ioc容器中。这就是一个天然的代理方法，原始的Bean就是`委托类`，在此处实现代理方法生成代理类，再将代理类加载进Ioc容器。

servlet的类继承层次（腾讯云二面）

### 十、算法

排序算法。快速排序的时间复杂度和空间复杂度。快排的排序算法是一个稳定的算法（腾讯CDG一面）

> https://github.com/CyC2018/CS-Notes/blob/master/notes/%E7%AE%97%E6%B3%95%20-%20%E6%8E%92%E5%BA%8F.md

> |       算法       | 稳定性 |          时间复杂度          | 空间复杂度 |           备注           |
> | :--------------: | :----: | :--------------------------: | :--------: | :----------------------: |
> |     选择排序     |   ×    |        N<sup>2</sup>         |     1      |                          |
> |     冒泡排序     |   √    |        N<sup>2</sup>         |     1      |                          |
> |     插入排序     |   √    |      N \~ N<sup>2</sup>      |     1      | 时间复杂度和初始顺序有关 |
> |     希尔排序     |   ×    | N 的若干倍乘于递增序列的长度 |     1      |      改进版插入排序      |
> |     快速排序     |   ×    |            NlogN             |    logN    |                          |
> | 三向切分快速排序 |   ×    |          N \~ NlogN          |    logN    |   适用于有大量重复主键   |
> |     归并排序     |   √    |            NlogN             |     N      |                          |
> |      堆排序      |   ×    |            NlogN             |     1      |    无法利用局部性原理    |

快速排序（深信服一面）

```java
class Solution {
    public int[] sortArray(int[] nums) {
        quickSort(nums, 0, nums.length - 1);
        return nums;
    }

    private void quickSort(int[] nums, int left, int right) {
        if (left < right) {
            int index = partition(nums, left, right);
            quickSort(nums, left, index - 1);
            quickSort(nums, index + 1, right);
        }
    }

    private int partition(int[] nums, int left, int right) {
        int pivot = nums[left];
        while (left < right) {
            while (left < right && nums[right] >= pivot) {
                right --;
            }
            nums[left] = nums[right];
            while (left < right && nums[left] <= pivot) {
                left ++;
            }
            nums[right] = nums[left];
        }
        nums[left] = pivot;
        return left;
    }
}
```

归并排序（腾讯云一面）

```java
class Solution{
    private void merge(int[] nums, int L1, int R1, int L2, int R2){
        int n = R1-L1+R2-L2+2;
        int[] temp = new int[n];
        int i = L1, j = L2, index = 0;
        while (i <= R1 && j <= R2){
            if (nums[i] <= nums[j]){
                temp[index++] = nums[i++];
            } else{
                temp[index++] = nums[j++];
            }
        }
        while (i <= R1){
            temp[index++] = nums[i++];
        }
        while (j <= R2){
            temp[index++] = nums[j++];
        }
        for (int k = 0; k < n; k++){
            nums[L1 + k] = temp[k];
        }
    }
    public void mergeSort(int[] nums, int left, int right){
        if (left < right){
           int mid = (left + right) / 2;
           mergeSort(nums, left, mid);
           mergeSort(nums, mid+1, right);
           merge(nums, left, mid, mid+1, right);
        }
    }
}
```

[152. 乘积最大子数组](https://leetcode-cn.com/problems/maximum-product-subarray/)（阿里云笔试）

```java
class Solution {
    public int maxProduct(int[] nums) {
        // res 记录最终的结果
        // lastMax记录最新的最大值
        // lastMin记录最新的最小值
        // 需要记录lastMin是因为当nums[i]为负数时，与lastMin相乘可能会使得结果最大
        int res = nums[0], lastMax = nums[0], lastMin = nums[0];
        for (int i = 1; i < nums.length; i++){
            // 转移方程：
            // lastMax = max(nums[i]*lastMax, nums[i]*lastMin, nums[i])
            // lastMin = min(nums[i]*lastMax, nums[i]*lastMin, nums[i])
            int a = nums[i];
            int b = nums[i] * lastMax;
            int c = nums[i] * lastMin;
            lastMax = Math.max(a, Math.max(b, c));
            lastMin = Math.min(a, Math.min(b, c));
            res = Math.max(res, lastMax);
        }
        return res;
    }
}
```

[219. 存在重复元素 II](https://leetcode-cn.com/problems/contains-duplicate-ii/)（华为Cloudbu）

```java
class Solution {
    public boolean containsNearbyDuplicate(int[] nums, int k) {
        Set<Integer> occ = new HashSet<Integer>();
        for (int i = 0; i < nums.length; i ++){
            if (occ.contains(nums[i])) return true;
            occ.add(nums[i]);
            if (occ.size() > k) occ.remove(nums[i - k]);
        }
        return false;
    }
}
```

[70. 爬楼梯](https://leetcode-cn.com/problems/climbing-stairs/)（快手一面）

[121. 买卖股票的最佳时机](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/)（快手一面）

[155. 最小栈](https://leetcode-cn.com/problems/min-stack/)（今日头条一面）

```java
class MinStack{
    Deque<Integer> xStack;
    // 设计一个辅助栈，其记录当前xStack对应的最小值
    // 由于stack栈先进后出的性质
    // 每次xStack入栈时，minStack入栈min(x, minStack.peek())
    // 每次xStack出栈时，minStack只需要出栈栈顶元素
    Deque<Integer> minStack;
    public MinStack(){
        xStack = new LinkedList<>();
        minStack = new LinkedList<>();
        minStack.push(Integer.MAX_VALUE);
    }
    public void push(int x){
        xStack.push(x);
        minStack.push(Math.min(minStack.peek(), x));
    }
    public void pop(){
        xStack.pop();
        minStack.pop();
    }
    public int top(){
        return xStack.peek();
    }
    public int getMin(){
        return minStack.peek();
    }
}
```

[206. 反转链表](https://leetcode-cn.com/problems/reverse-linked-list/)（今日头条一面）

```java
class Solution {
    public ListNode reverseList(ListNode head) {
        // bad case
        if (head == null || head.next == null) return head;
        ListNode last = reverseList(head.next);
        head.next.next = head;
        // 当链表递归反转之后，新的头节点是last，而之前的head变成了最后一个节点，链表的末尾要指向null
        head.next = null;
        return last;
    }
}
```

[146. LRU 缓存机制](https://leetcode-cn.com/problems/lru-cache/)（淘宝一面，深信服一面）

```java
class LRUCache {
    LinkedHashMap<Integer, Integer> map = new LinkedHashMap<>();
    int capacity;

    public LRUCache(int capacity){
        this.capacity = capacity;
    }
    public int get(int key){
        if(!map.containsKey(key)){
            return -1;
        } else{
            makeLast(key);
            return map.get(key);
        }
    }
    public void put(int key, int value){
        map.put(key, value);
        makeLast(key);
        if (map.size() > capacity){
            map.remove(map.keySet().iterator().next());
        }
    }
    public void makeLast(int key){
        int value = map.get(key);
        map.remove(key);
        map.put(key, value);
    }
}
```

输入一个数字，打印出嵌套的正方形。设输入 n；如果 n 是 奇数，则打印 1 ，5 ，9..., n 的嵌套正方形；如果 n 是偶数，则打印出 1 , 5 ,9..., n - 1 的嵌套正方形；最大n 设置为17；例子：如果 输入 n = 9， 则打印出下面的图形（淘宝一面）

![image-20210226193459294](C:\Users\cuimaolin\AppData\Roaming\Typora\typora-user-images\image-20210226193459294.png)

```java
class Solution{
    public void printNestedArray(int n){
        if (n % 2 == 0) n--;
        n = n - (n - 1) % 4;
        boolean[][] ans = new boolean[n][n];
        int start = 0;
        int length = n;
        while(length > 0){
            fillArray(ans, start, length);
            start += 2;
            length -= 4;
        }
        for (int i = 0; i < n; i ++){
            for (int j = 0; j < n; j++){
                if (ans[i][j]){
                    System.out.print("+ ");
                } else{
                    System.out.print("  ");
                }
            }
            System.out.println();
        }
    }
    public void fillArray(boolean[][] ans, int start, int length){
        for (int i = start; i < start + length; i++){
            ans[i][start] = true;
            ans[start][i] = true;
            ans[i][start+length-1] = true;
            ans[start+length-1][i] = true;
        }
    }
}
```

一个蛋糕三刀切成四块（腾讯CDG一面）

长度为n的数组，进行逆序排序？（腾讯CDG一面）

```java
class Solution{
    public void reverseArray(int[] nums){
        int right = nums.length - 1;
        int left = 0;
        while(left < right){
            int tmp = nums[right];
            nums[right] = nums[left];
            nums[left] = tmp;
            left ++;
            right --;
        }
    }
}
```

[剑指 Offer 25. 合并两个排序的链表](https://leetcode-cn.com/problems/he-bing-liang-ge-pai-xu-de-lian-biao-lcof/)（快手二面）

```java
class Solution{
    public ListNode mergeListNode(ListNode head1, ListNode head2){
        ListNode head = new ListNode(-1);
        ListNode dummy = head;
        while(head1 != null && head2 != null){
            if (head1.val < head2.val){
                dummy.next = new ListNode(head1.val);
                head1 = head1.next;
            } else{
                dummy.next = new ListNode(head2.val);
                head2 = head2.next;
            }
            dummy = dummy.next;
        }
        if (head1 != null){
            dummy.next = head1;
        } else if (head2 != null){
            dummy.next = head2;
        }
        return head.next;
    }
}
```

[剑指 Offer 42. 连续子数组的最大和](https://leetcode-cn.com/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/)（腾讯云二面）

```java
class Solution {
    public int maxSubArray(int[] nums) {
        int res = nums[0];
        for (int i = 1; i < nums.length; i ++){
            nums[i] = Math.max(nums[i], nums[i] + nums[i - 1]);
            res = Math.max(res, nums[i]);
        }
        return res;
    }
}
```

求两个数的最大公约数gcd（腾讯云二面）

```java
class SoluctionTxCloud{
    // 求两个数的最大公约数
    public int gcd(int a, int b){
        if (b == 0) return a;
        return gcd(b, a % b);
    }

    // 求两个数的最大公倍数
    public int lcm(int a, int b){
        return a / gcd(a, b) * b;
    }
}
```

[剑指 Offer 04. 二维数组中的查找](https://leetcode-cn.com/problems/er-wei-shu-zu-zhong-de-cha-zhao-lcof/)（今日头条测开二面）

```java
class Solution{
    public boolean findNumberIn2DArray(int[][] matrix, int target){
        if (matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return false;
        }
        int rows = matrix.length;
        int cols = matrix[0].length;
        int row = 0;
        int col = cols - 1;
        while(row < rows && col >= 0){
            if (matrix[row][col] > target){
                col --;
            } else if (matrix[row][col] < target){
                row ++;
            } else{
                return true;
            }
        }
        return false;
    }
}
```

单例模式（腾讯TEG一面）

[704. 二分查找](https://leetcode-cn.com/problems/binary-search/)（腾讯TEG一面）

[20. 有效的括号](https://leetcode-cn.com/problems/valid-parentheses/)（腾讯TEG一面）

最大堆最小堆怎么维护（腾讯TEG一面）

算法题：[逛街](https://www.nowcoder.com/questionTerminal/35fac8d69f314e958a150c141894ef6a)（==腾讯CDG事务开发一面==）

算法题：[剑指 Offer 42. 连续子数组的最大和](https://leetcode-cn.com/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/)（==字节系统研发一面==）

